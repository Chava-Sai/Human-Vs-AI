{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1hm_jZeIjLn0zpTpRSKFHe_SbBHT105tg",
      "authorship_tag": "ABX9TyOub3mgBTcb+/Tfw4UouQN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2b499ba196a407aad5e04f91a78870e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf95152577bd4c85a9daeaf03b9c4516",
              "IPY_MODEL_beb49429b2a34a28be062e48bc599a1d",
              "IPY_MODEL_0c5441e3d8dd4c6a920ceea5ff6c9867"
            ],
            "layout": "IPY_MODEL_a8162a8c895d4d5cb8356c502472ce93"
          }
        },
        "cf95152577bd4c85a9daeaf03b9c4516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c928d10f3fbd4be0bbd54ba1da9a14f2",
            "placeholder": "​",
            "style": "IPY_MODEL_5e24dee1d0864d7292ffefd463b39a72",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "beb49429b2a34a28be062e48bc599a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007d442c7b5e4643ac9361c8f9cfa4a7",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56b05c764824930ac339808ff5ea4c0",
            "value": 25
          }
        },
        "0c5441e3d8dd4c6a920ceea5ff6c9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc1d4a9f29d468d9b199fa837846903",
            "placeholder": "​",
            "style": "IPY_MODEL_d8daec56ef39401892f0c769bc7a4b2a",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.52kB/s]"
          }
        },
        "a8162a8c895d4d5cb8356c502472ce93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c928d10f3fbd4be0bbd54ba1da9a14f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e24dee1d0864d7292ffefd463b39a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "007d442c7b5e4643ac9361c8f9cfa4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56b05c764824930ac339808ff5ea4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc1d4a9f29d468d9b199fa837846903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8daec56ef39401892f0c769bc7a4b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b71a94a5c24092964c874bf13b8600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e8432fcfcc440cab026f3aaea7393cd",
              "IPY_MODEL_ac20e7d6460c4b84be722bf7c9961791",
              "IPY_MODEL_693991a4d5724fea87d399b7b529e848"
            ],
            "layout": "IPY_MODEL_bb76ed827ce441bdb3e1b962ac037d1b"
          }
        },
        "4e8432fcfcc440cab026f3aaea7393cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8071685e9094f0fbf30e6f641333c81",
            "placeholder": "​",
            "style": "IPY_MODEL_adeb07fd038943238b051e8977d51d9c",
            "value": "config.json: 100%"
          }
        },
        "ac20e7d6460c4b84be722bf7c9961791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4ba17f6cb9454a8912990b47c1f54f",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6046351808c4c9181cda56362a3749d",
            "value": 498
          }
        },
        "693991a4d5724fea87d399b7b529e848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ffdca8cc2ce4e50903803d21ed55a66",
            "placeholder": "​",
            "style": "IPY_MODEL_9578e2826ec44bfba3991a8bfcb2796f",
            "value": " 498/498 [00:00&lt;00:00, 60.5kB/s]"
          }
        },
        "bb76ed827ce441bdb3e1b962ac037d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8071685e9094f0fbf30e6f641333c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adeb07fd038943238b051e8977d51d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4ba17f6cb9454a8912990b47c1f54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6046351808c4c9181cda56362a3749d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ffdca8cc2ce4e50903803d21ed55a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9578e2826ec44bfba3991a8bfcb2796f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa03470d19154f18810bcd6fd90e4c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9680f5f3c2e4f6e8d432b1eef131077",
              "IPY_MODEL_a4afe0c911304e3eb5b71dc6625e6084",
              "IPY_MODEL_f19aea02809f44d19ec1e055b00bdbab"
            ],
            "layout": "IPY_MODEL_70fecdb0b38845f98c60f1c7c638ad85"
          }
        },
        "a9680f5f3c2e4f6e8d432b1eef131077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9cab6502254d768021cfde1deb3d88",
            "placeholder": "​",
            "style": "IPY_MODEL_f13d5a3243c04d81b8f822dd5c615502",
            "value": "vocab.json: "
          }
        },
        "a4afe0c911304e3eb5b71dc6625e6084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaeb052c4e29492ebf33d1fcd0680832",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb146c7a53094214a0c50c468c647dcf",
            "value": 1
          }
        },
        "f19aea02809f44d19ec1e055b00bdbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170c4bdade0d4841b957dd2f946a27a0",
            "placeholder": "​",
            "style": "IPY_MODEL_add6560fa9a146dcaa027307848cf9ea",
            "value": " 899k/? [00:00&lt;00:00, 35.3MB/s]"
          }
        },
        "70fecdb0b38845f98c60f1c7c638ad85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9cab6502254d768021cfde1deb3d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13d5a3243c04d81b8f822dd5c615502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaeb052c4e29492ebf33d1fcd0680832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "eb146c7a53094214a0c50c468c647dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "170c4bdade0d4841b957dd2f946a27a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add6560fa9a146dcaa027307848cf9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8561999e14cb4b7095e5d8991c031e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_808b7e8d08e84d628c28311da122954c",
              "IPY_MODEL_c3312d79a8f941d2abaed2eed52fe576",
              "IPY_MODEL_af31d1793eff471193d7bbd6ad6de5e7"
            ],
            "layout": "IPY_MODEL_d7f89322675c4708b61854563f61e828"
          }
        },
        "808b7e8d08e84d628c28311da122954c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_815f3207790c4444ad164d682f65164e",
            "placeholder": "​",
            "style": "IPY_MODEL_8e533e796c7c4c9a90f58d921841faaa",
            "value": "merges.txt: "
          }
        },
        "c3312d79a8f941d2abaed2eed52fe576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e51f6c1bc146fab929021bfd25d9ce",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be5102373ca24d16b921e127ccbc6aae",
            "value": 1
          }
        },
        "af31d1793eff471193d7bbd6ad6de5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c044d96b72d04550b5d989361786f64f",
            "placeholder": "​",
            "style": "IPY_MODEL_33abe59f1ae84cbca32eadb022cf6b0c",
            "value": " 456k/? [00:00&lt;00:00, 32.3MB/s]"
          }
        },
        "d7f89322675c4708b61854563f61e828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815f3207790c4444ad164d682f65164e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e533e796c7c4c9a90f58d921841faaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e51f6c1bc146fab929021bfd25d9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "be5102373ca24d16b921e127ccbc6aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c044d96b72d04550b5d989361786f64f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33abe59f1ae84cbca32eadb022cf6b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "617317b31ec6498eb52afc669dd711b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a537e3c54e4943f3b04dfa5a9e79d013",
              "IPY_MODEL_35a44908e1574545b192944fa40e3447",
              "IPY_MODEL_97ed4c3a895f49cbabc8fd9b5094f6b7"
            ],
            "layout": "IPY_MODEL_fb7f3b79893a4db28ce90f1f1ee733d6"
          }
        },
        "a537e3c54e4943f3b04dfa5a9e79d013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f31b582b0014114b799575195ba999b",
            "placeholder": "​",
            "style": "IPY_MODEL_55d211d15784457fbfb99414b4fc5a0f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "35a44908e1574545b192944fa40e3447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29baa43337a54c1484c6cb34a7cab820",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ceee21a3da04f8aacbe26ca57f56a68",
            "value": 150
          }
        },
        "97ed4c3a895f49cbabc8fd9b5094f6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_151202297fd04a88a48e9afcd9ae1934",
            "placeholder": "​",
            "style": "IPY_MODEL_4d30da4219464806b86892fd58f0229b",
            "value": " 150/150 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "fb7f3b79893a4db28ce90f1f1ee733d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f31b582b0014114b799575195ba999b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d211d15784457fbfb99414b4fc5a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29baa43337a54c1484c6cb34a7cab820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ceee21a3da04f8aacbe26ca57f56a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "151202297fd04a88a48e9afcd9ae1934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d30da4219464806b86892fd58f0229b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47bc0b8b0dec4fcfba988047aefd05e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1d5181ca0794eb0a734d3e81bf114b5",
              "IPY_MODEL_4dcb2228532d419286d1647190ca2d16",
              "IPY_MODEL_9c7bac4a9ae3459a87224128035d0924"
            ],
            "layout": "IPY_MODEL_25422d3dfef340d1b22c78ad41397cf9"
          }
        },
        "d1d5181ca0794eb0a734d3e81bf114b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a0a9aeb41b458392ca0b0e042004f1",
            "placeholder": "​",
            "style": "IPY_MODEL_d19d0eb3d0cc4ad688df6d7f91252dfe",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4dcb2228532d419286d1647190ca2d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b57e7ecd804a1b8b5a1313f6039acc",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efe0728163a9462b92458041f305ceb6",
            "value": 498627950
          }
        },
        "9c7bac4a9ae3459a87224128035d0924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fc2ef0db6844a89bcf74a5e9d32ba5d",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c72004a6a14487ba95af4730f2953e",
            "value": " 499M/499M [00:01&lt;00:00, 693MB/s]"
          }
        },
        "25422d3dfef340d1b22c78ad41397cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a0a9aeb41b458392ca0b0e042004f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19d0eb3d0cc4ad688df6d7f91252dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23b57e7ecd804a1b8b5a1313f6039acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe0728163a9462b92458041f305ceb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fc2ef0db6844a89bcf74a5e9d32ba5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c72004a6a14487ba95af4730f2953e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd68c2c5379242d5bee4f9748c5eed2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_929987bb8725401baf726872c13af560",
              "IPY_MODEL_6185c498aaee42248ffdf99a85754573",
              "IPY_MODEL_b1d82c62c3b441c7971ef12dbdbc447c"
            ],
            "layout": "IPY_MODEL_3fc7517f0d9046d78a6ebcff4eedca91"
          }
        },
        "929987bb8725401baf726872c13af560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048358a28fd0472b9d2c91b75e916148",
            "placeholder": "​",
            "style": "IPY_MODEL_6f218600b3b441d396927ec3faa9cad9",
            "value": "Scoring VAL (full for threshold):   1%"
          }
        },
        "6185c498aaee42248ffdf99a85754573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d7e5b1ccfe4c2180ad6308504b406f",
            "max": 12500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_901c91df81db40349985c2331471120d",
            "value": 140
          }
        },
        "b1d82c62c3b441c7971ef12dbdbc447c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db659e60ef7430692656cbe901b1a18",
            "placeholder": "​",
            "style": "IPY_MODEL_e2b3bbdf85ab44608e1225688bb5054c",
            "value": " 140/12500 [00:59&lt;1:26:54,  2.37batch/s]"
          }
        },
        "3fc7517f0d9046d78a6ebcff4eedca91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048358a28fd0472b9d2c91b75e916148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f218600b3b441d396927ec3faa9cad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d7e5b1ccfe4c2180ad6308504b406f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901c91df81db40349985c2331471120d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db659e60ef7430692656cbe901b1a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b3bbdf85ab44608e1225688bb5054c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e19974c2784a308a9dacfc2cf76399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6c2eeb38ace4354ab95c937b7dcaa36",
              "IPY_MODEL_2f09d69792844bb98f411cd4f6e3f5dc",
              "IPY_MODEL_fc5145b5c36c4499b89da1d46f202fe8"
            ],
            "layout": "IPY_MODEL_e2092995020e45a99716de7dbc9b8a7d"
          }
        },
        "b6c2eeb38ace4354ab95c937b7dcaa36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87881aab0d6247e6a2bcb196642a5674",
            "placeholder": "​",
            "style": "IPY_MODEL_5be005ae3d9f4fa9b1c1891363acc16a",
            "value": "tokenizer_config.json: "
          }
        },
        "2f09d69792844bb98f411cd4f6e3f5dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c81649c31c64dc3a5dc51d212c0820e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c145d4890ca4388bb3bd2d73889e9c6",
            "value": 1
          }
        },
        "fc5145b5c36c4499b89da1d46f202fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2ad4b4ef334f8dad35f91cbc2dbfe2",
            "placeholder": "​",
            "style": "IPY_MODEL_4c3f055181c040569796ad0dc8a9ac6d",
            "value": " 7.88k/? [00:00&lt;00:00, 788kB/s]"
          }
        },
        "e2092995020e45a99716de7dbc9b8a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87881aab0d6247e6a2bcb196642a5674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be005ae3d9f4fa9b1c1891363acc16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c81649c31c64dc3a5dc51d212c0820e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8c145d4890ca4388bb3bd2d73889e9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b2ad4b4ef334f8dad35f91cbc2dbfe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3f055181c040569796ad0dc8a9ac6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d80a3634bb2440db4f5dc9a9355bf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3c1da2a42f441fd961eab8e5dae3fc8",
              "IPY_MODEL_b6c192912800443f9cc946bd11197876",
              "IPY_MODEL_caf698e9284040d2b1583b8a31d9fafe"
            ],
            "layout": "IPY_MODEL_1f1ac3e02da043a1917d6d07acb7e562"
          }
        },
        "c3c1da2a42f441fd961eab8e5dae3fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e7a27a668142c88690c8ec2bf714f9",
            "placeholder": "​",
            "style": "IPY_MODEL_ec52c3507b3f479fad1c8f23cfc282b1",
            "value": "vocab.json: "
          }
        },
        "b6c192912800443f9cc946bd11197876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9674020e3de94b919d17bfbf605f8750",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_872394336e40425f8d5596b85d324f04",
            "value": 1
          }
        },
        "caf698e9284040d2b1583b8a31d9fafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118ceaf4a3a94d3c96884f6e938a064c",
            "placeholder": "​",
            "style": "IPY_MODEL_e850a2585edb4a278973a4bb7f73793f",
            "value": " 777k/? [00:00&lt;00:00, 32.2MB/s]"
          }
        },
        "1f1ac3e02da043a1917d6d07acb7e562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e7a27a668142c88690c8ec2bf714f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec52c3507b3f479fad1c8f23cfc282b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9674020e3de94b919d17bfbf605f8750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "872394336e40425f8d5596b85d324f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "118ceaf4a3a94d3c96884f6e938a064c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e850a2585edb4a278973a4bb7f73793f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f36b80e06e4497eaf22ca4b77e440d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7d23ee9d8e14c7fb72d866960b96c11",
              "IPY_MODEL_3efbe18de1794677be4baedaa195b496",
              "IPY_MODEL_5f07765be3c54cebbc76a291a450a343"
            ],
            "layout": "IPY_MODEL_edeb721609684d67ae8146c7d706e130"
          }
        },
        "b7d23ee9d8e14c7fb72d866960b96c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c659d45d0cb44edbb69db00956163202",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5098bb846945219306445a6f468c5e",
            "value": "merges.txt: "
          }
        },
        "3efbe18de1794677be4baedaa195b496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21d5e43b7a31497e99597cb8e4a61393",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1e00e586c4d41d7b88be7fcc266eee2",
            "value": 1
          }
        },
        "5f07765be3c54cebbc76a291a450a343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc5ecb2d6a6d4dc6bf53614f2d17bcf4",
            "placeholder": "​",
            "style": "IPY_MODEL_2df8089836524441a1a691e96d39ffcf",
            "value": " 442k/? [00:00&lt;00:00, 36.2MB/s]"
          }
        },
        "edeb721609684d67ae8146c7d706e130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c659d45d0cb44edbb69db00956163202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5098bb846945219306445a6f468c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21d5e43b7a31497e99597cb8e4a61393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a1e00e586c4d41d7b88be7fcc266eee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc5ecb2d6a6d4dc6bf53614f2d17bcf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df8089836524441a1a691e96d39ffcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9bb410ba244797889b58c4d219411c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0df6bc8d210c41fd858f8f220831f0b9",
              "IPY_MODEL_9ca3141a6b674785b20ea77fae00180a",
              "IPY_MODEL_51e7c3bfdc1a4db3884bf1d43c7a1efd"
            ],
            "layout": "IPY_MODEL_195836db110f4c47b13630df0e9d8ee5"
          }
        },
        "0df6bc8d210c41fd858f8f220831f0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13fa13bbff8e4bad8ecfed6d9fd7e25a",
            "placeholder": "​",
            "style": "IPY_MODEL_102a6cdaf72147b09c6e00d919ad70d8",
            "value": "tokenizer.json: "
          }
        },
        "9ca3141a6b674785b20ea77fae00180a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dc18909cdd44c8d8968a5712d3b340c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3c7611f762442f6a44ad9dadd559d2d",
            "value": 1
          }
        },
        "51e7c3bfdc1a4db3884bf1d43c7a1efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034e878984374ee6a9069bdc1fb39116",
            "placeholder": "​",
            "style": "IPY_MODEL_55d04ecea9884bf0aeb071685507bb52",
            "value": " 2.06M/? [00:00&lt;00:00, 92.0MB/s]"
          }
        },
        "195836db110f4c47b13630df0e9d8ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13fa13bbff8e4bad8ecfed6d9fd7e25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102a6cdaf72147b09c6e00d919ad70d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dc18909cdd44c8d8968a5712d3b340c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a3c7611f762442f6a44ad9dadd559d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "034e878984374ee6a9069bdc1fb39116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d04ecea9884bf0aeb071685507bb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ab446b179784ec4a8942b49b18c1069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4d7a7d8eb83473b80aca51c7761ad74",
              "IPY_MODEL_3f7018c86bbd4127abbe40c13fab9e18",
              "IPY_MODEL_63a49a362d3949d79fa54156da853323"
            ],
            "layout": "IPY_MODEL_10b1d88d296d491e8eb90c828b76c830"
          }
        },
        "b4d7a7d8eb83473b80aca51c7761ad74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b27cd4158e6a44e788d9febc2136f47b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f4251f4713b497391d640772e8d9c4b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3f7018c86bbd4127abbe40c13fab9e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e07601ef71346ff9f8a61eb8c6371ef",
            "max": 958,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d8e5cd9d06d4863afdc3125f8367ea4",
            "value": 958
          }
        },
        "63a49a362d3949d79fa54156da853323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7651fc6995b0459fb7b310a7a6830540",
            "placeholder": "​",
            "style": "IPY_MODEL_15ff8fc79cd14060b8f836f8ae69ea56",
            "value": " 958/958 [00:00&lt;00:00, 140kB/s]"
          }
        },
        "10b1d88d296d491e8eb90c828b76c830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b27cd4158e6a44e788d9febc2136f47b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4251f4713b497391d640772e8d9c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e07601ef71346ff9f8a61eb8c6371ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8e5cd9d06d4863afdc3125f8367ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7651fc6995b0459fb7b310a7a6830540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ff8fc79cd14060b8f836f8ae69ea56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08a8988a35c54a338efd8104970956a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_505c8d99a7304cb4a2c70ddcd8d631cd",
              "IPY_MODEL_c121003aebbf48be9269ff099cf87ad5",
              "IPY_MODEL_10182ef9d86e497985fc16e772cce2b5"
            ],
            "layout": "IPY_MODEL_21262084dd77494d8509e1f25c7045f3"
          }
        },
        "505c8d99a7304cb4a2c70ddcd8d631cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb025384b6b483d8eace538f8fe8b07",
            "placeholder": "​",
            "style": "IPY_MODEL_8c72470ea6244bdfbe57414512ace245",
            "value": "config.json: 100%"
          }
        },
        "c121003aebbf48be9269ff099cf87ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84db0f7ac2c4f13812c1e7703db2c78",
            "max": 700,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9172c0ebd384bf2ad118179aa20013e",
            "value": 700
          }
        },
        "10182ef9d86e497985fc16e772cce2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27e14e2931f54e94a670dcdf7a741f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_c420c293ab9040759cdee41212e61660",
            "value": " 700/700 [00:00&lt;00:00, 93.2kB/s]"
          }
        },
        "21262084dd77494d8509e1f25c7045f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb025384b6b483d8eace538f8fe8b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c72470ea6244bdfbe57414512ace245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c84db0f7ac2c4f13812c1e7703db2c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9172c0ebd384bf2ad118179aa20013e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27e14e2931f54e94a670dcdf7a741f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c420c293ab9040759cdee41212e61660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e05b590103645aeb291c931fd74b198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3847a3c6d35b4e7fa44349b429ce0b64",
              "IPY_MODEL_b99266977e824c989744c55f211f6db3",
              "IPY_MODEL_9d5033de6d48447abd6238f22536fe41"
            ],
            "layout": "IPY_MODEL_7ae0952adf744c819645e34d4e88adc2"
          }
        },
        "3847a3c6d35b4e7fa44349b429ce0b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01586cc533d04754be81b00072666a07",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd0a5e6c1544a46b62d71e3d1aeddd3",
            "value": "model.safetensors: 100%"
          }
        },
        "b99266977e824c989744c55f211f6db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8ec2a1c5ac43a3924cb6147c7c2317",
            "max": 12121539344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3230cdcf020e40e7b2eab212432e9574",
            "value": 12121539344
          }
        },
        "9d5033de6d48447abd6238f22536fe41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51fb9606892a462ea321d3756ed579c1",
            "placeholder": "​",
            "style": "IPY_MODEL_5ca64124252e484495f960332f0e8d25",
            "value": " 12.1G/12.1G [00:58&lt;00:00, 451MB/s]"
          }
        },
        "7ae0952adf744c819645e34d4e88adc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01586cc533d04754be81b00072666a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd0a5e6c1544a46b62d71e3d1aeddd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8ec2a1c5ac43a3924cb6147c7c2317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3230cdcf020e40e7b2eab212432e9574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51fb9606892a462ea321d3756ed579c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ca64124252e484495f960332f0e8d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c88236cf5cc043fea0810f55407da2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64ca4a69541f4d489e4f4b63d0e7f26b",
              "IPY_MODEL_03eeeb2f0b0c4bd7a52cb663f29ec73b",
              "IPY_MODEL_7544a0963cde482fba2ebb333c81af22"
            ],
            "layout": "IPY_MODEL_b312c18ed85b4125b367ef604a0cb715"
          }
        },
        "64ca4a69541f4d489e4f4b63d0e7f26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b27a6037cf041f9bd5054daee645177",
            "placeholder": "​",
            "style": "IPY_MODEL_8d1a1a643d1543938ee3413757d95f40",
            "value": "Epoch 1: 100%"
          }
        },
        "03eeeb2f0b0c4bd7a52cb663f29ec73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a53a12ea6d47fbad06ce600df062ed",
            "max": 6250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5226568cc64330a61f250af8ef9fe4",
            "value": 6250
          }
        },
        "7544a0963cde482fba2ebb333c81af22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10a340de31fd4577bc81558dbc054a42",
            "placeholder": "​",
            "style": "IPY_MODEL_60efe570e5d445b691b3e21bc3f790e8",
            "value": " 6250/6250 [2:38:50&lt;00:00,  1.52s/batch, loss=0.152, skipped=0]"
          }
        },
        "b312c18ed85b4125b367ef604a0cb715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b27a6037cf041f9bd5054daee645177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1a1a643d1543938ee3413757d95f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a53a12ea6d47fbad06ce600df062ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5226568cc64330a61f250af8ef9fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10a340de31fd4577bc81558dbc054a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60efe570e5d445b691b3e21bc3f790e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "469f4d83d5974911a83f22b73cffb6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9f524313cb4413ac31108e88f8cc1b",
              "IPY_MODEL_294e35a3ceb74cb98b1d00bb71ed7e14",
              "IPY_MODEL_3c4fba002100479ebba71d9d404f5c36"
            ],
            "layout": "IPY_MODEL_50e4c9b8210545ebade3906343e5c2db"
          }
        },
        "7b9f524313cb4413ac31108e88f8cc1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3091ec7159d443b88e84deed05d9a703",
            "placeholder": "​",
            "style": "IPY_MODEL_893f03937a7f48e5a80279f2ce597b35",
            "value": "Validating (VAL): 100%"
          }
        },
        "294e35a3ceb74cb98b1d00bb71ed7e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b1625c46df4012ab8f7d6c9db781d3",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e35f44164a724b7aad26982e09ddfe8b",
            "value": 3125
          }
        },
        "3c4fba002100479ebba71d9d404f5c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742a342d16a648acbe5bb693dbe0f755",
            "placeholder": "​",
            "style": "IPY_MODEL_765c8fcbf04341eea4cdf5969d2597de",
            "value": " 3125/3125 [21:07&lt;00:00,  2.47batch/s]"
          }
        },
        "50e4c9b8210545ebade3906343e5c2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3091ec7159d443b88e84deed05d9a703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893f03937a7f48e5a80279f2ce597b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5b1625c46df4012ab8f7d6c9db781d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e35f44164a724b7aad26982e09ddfe8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "742a342d16a648acbe5bb693dbe0f755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765c8fcbf04341eea4cdf5969d2597de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa9edf2e119845e0a518af7ce8072d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0d87ddeb98948b2aaedf3b15c0c0fa6",
              "IPY_MODEL_d04e39eb0a614e2c8db459a0ce9d5c28",
              "IPY_MODEL_a2fcbc22065a457fa488b4afd62ec669"
            ],
            "layout": "IPY_MODEL_f0550b33ebef47508942dab8e1acc41e"
          }
        },
        "d0d87ddeb98948b2aaedf3b15c0c0fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f14a40f0dc04a639cfe9cccbb0c68d1",
            "placeholder": "​",
            "style": "IPY_MODEL_823c98cdb7c741589d36c0ae68431b7b",
            "value": "Scoring VAL (final): 100%"
          }
        },
        "d04e39eb0a614e2c8db459a0ce9d5c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704388380ec14c3d8a525079b1e0a5a7",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f13a24e98cac4b469164d342113d9322",
            "value": 3125
          }
        },
        "a2fcbc22065a457fa488b4afd62ec669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efe70aa9c83e4bfb8fae7c09307a4a49",
            "placeholder": "​",
            "style": "IPY_MODEL_892ec6631e7849e2a6184487dc13ae5f",
            "value": " 3125/3125 [21:09&lt;00:00,  2.47batch/s]"
          }
        },
        "f0550b33ebef47508942dab8e1acc41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f14a40f0dc04a639cfe9cccbb0c68d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823c98cdb7c741589d36c0ae68431b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704388380ec14c3d8a525079b1e0a5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13a24e98cac4b469164d342113d9322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efe70aa9c83e4bfb8fae7c09307a4a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892ec6631e7849e2a6184487dc13ae5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a593adb7a134868b467f5411854cb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e303518c64345edbf504102067abd82",
              "IPY_MODEL_74d4b52bffb34c08b0a572807129e566",
              "IPY_MODEL_63b81b1bd87c427f83953e258ac89d8e"
            ],
            "layout": "IPY_MODEL_ea8ce5f7ed5048d287105123e8d9cb63"
          }
        },
        "0e303518c64345edbf504102067abd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbac2def35ac4f508fb8d345d5b358b5",
            "placeholder": "​",
            "style": "IPY_MODEL_d127020d25ce4cb5b925b08525ad7842",
            "value": "Scoring TEST: 100%"
          }
        },
        "74d4b52bffb34c08b0a572807129e566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef54a7902edf4cfb80c544eeca0b8103",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_365ea0a0b6fb4968b4e0ee8310a7dc8d",
            "value": 125
          }
        },
        "63b81b1bd87c427f83953e258ac89d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac09a8fac6304105a94c16053eeb4ae9",
            "placeholder": "​",
            "style": "IPY_MODEL_350a818080044addb614c157062c2c38",
            "value": " 125/125 [00:51&lt;00:00,  2.42batch/s]"
          }
        },
        "ea8ce5f7ed5048d287105123e8d9cb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbac2def35ac4f508fb8d345d5b358b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d127020d25ce4cb5b925b08525ad7842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef54a7902edf4cfb80c544eeca0b8103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365ea0a0b6fb4968b4e0ee8310a7dc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac09a8fac6304105a94c16053eeb4ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350a818080044addb614c157062c2c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chava-Sai/Human-Vs-AI/blob/main/Human_VS_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task -  1 Attempt - 1"
      ],
      "metadata": {
        "id": "n57kEugYQWrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI2gEJLE66OM",
        "outputId": "5b44c26a-c1ec-4a1e-dede-f15afda50eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct  5 22:59:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   31C    P0             49W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "print(\"Device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8JrkdR17-nc",
        "outputId": "29aa030c-1ec0-4856-fd01-4f3bf3197853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jy52wnry4ebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== GPU sanity check (prints which GPU we got) ====\n",
        "!nvidia-smi\n",
        "\n",
        "# ==== Install dependencies (CUDA 12.x wheel for torch; adjust if needed) ====\n",
        "# We keep versions stable for reproducibility.\n",
        "!pip -q install torch --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install transformers==4.44.2 pandas pyarrow scikit-learn tqdm\n",
        "\n",
        "# ==== (Optional) Restart Uvicorn/Colab's runtime output if it complains; usually not needed ====\n",
        "\n",
        "# ==== Mount Google Drive so we can load/save datasets and checkpoints persistently ====\n",
        "from google.colab import drive  # Colab helper to mount Drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Prompts you to authorize once"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdibNtUJ8B0H",
        "outputId": "842bae8b-0255-4710-9b5b-2ae8edb3ea22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct  5 22:59:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   31C    P0             49W /  400W |       5MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Silence tokenizer parallelism warning (must be set BEFORE importing transformers) ====\n",
        "import os  # OS/env utils\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # avoids fork/parallelism deadlock warnings\n",
        "\n",
        "# ==== Standard imports ====\n",
        "import random  # seeds\n",
        "from dataclasses import dataclass  # clean config container\n",
        "from typing import Dict, List, Optional, Tuple  # type hints\n",
        "\n",
        "import numpy as np  # numerics\n",
        "import pandas as pd  # parquet I/O\n",
        "from tqdm import tqdm  # progress bars\n",
        "\n",
        "# ==== Metrics from scikit-learn ====\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "# ==== PyTorch core ====\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ==== Hugging Face Transformers ====\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "\n",
        "# ==== Confirm device ====\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ==== Reproducibility helper ====\n",
        "def set_seed(seed: int) -> None:\n",
        "    random.seed(seed)                  # Python RNG\n",
        "    np.random.seed(seed)               # NumPy RNG\n",
        "    torch.manual_seed(seed)            # PyTorch CPU RNG\n",
        "    torch.cuda.manual_seed_all(seed)   # All visible GPUs\n",
        "    torch.backends.cudnn.deterministic = True  # Deterministic convs\n",
        "    torch.backends.cudnn.benchmark = False     # Disable autotuner (more reproducible)\n",
        "\n",
        "# ==== Configuration dataclass (you can edit paths & hyperparams here) ====\n",
        "@dataclass\n",
        "class Config:\n",
        "    # ---- PATHS: set these to your files in Drive ----\n",
        "    # Example: put your parquet files at /content/drive/MyDrive/semeval_taskA/\n",
        "    data_dir: str = \"/content/drive/MyDrive/SemEval-2026-Task13\"\n",
        "    train_parquet: str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_training_set_1.parquet\"\n",
        "    val_parquet: str   = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet\"\n",
        "    test_parquet: str  = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"  # optional; comment if not available\n",
        "\n",
        "    # ---- Model (allowed general-purpose code model) ----\n",
        "    model_name: str = \"microsoft/codebert-base\"\n",
        "\n",
        "    # ---- Tokenization / batching ----\n",
        "    max_length: int = 512             # truncate long code sequences\n",
        "    train_batch_size: int = 16        # A100 can handle 16 easily; drop to 8 on T4\n",
        "    eval_batch_size: int = 32         # evaluation can be larger\n",
        "    gradient_accumulation_steps: int = 1  # set >1 if you want a bigger effective batch\n",
        "\n",
        "    # ---- Optimization ----\n",
        "    epochs: int = 3                   # start small; we’ll iterate later\n",
        "    lr: float = 2e-5                  # good LR for transformer fine-tune\n",
        "    weight_decay: float = 0.01        # AdamW regularization\n",
        "    warmup_ratio: float = 0.1         # % of steps for LR warmup\n",
        "    max_grad_norm: float = 1.0        # gradient clipping\n",
        "\n",
        "    # ---- Dataloading ----\n",
        "    num_workers: int = 2              # Colab-friendly; bump to 4 if stable\n",
        "\n",
        "    # ---- Reproducibility ----\n",
        "    seed: int = 42\n",
        "\n",
        "    # ---- Evaluation settings (normalized lang names) ----\n",
        "    seen_languages: Tuple[str, ...] = (\"cpp\", \"python\", \"java\")\n",
        "    unseen_languages: Tuple[str, ...] = (\"go\", \"php\", \"csharp\", \"c\", \"javascript\")\n",
        "    seen_domains: Tuple[str, ...] = (\"algorithmic\",)\n",
        "    unseen_domains: Tuple[str, ...] = (\"research\", \"production\")\n",
        "\n",
        "    # ---- Output directories ----\n",
        "    out_dir: str = \"/content/drive/MyDrive/semeval_taskA_outputs\"\n",
        "    ckpt_name: str = \"taskA_codebert_best.pt\"\n",
        "\n",
        "cfg = Config()             # instantiate config\n",
        "set_seed(cfg.seed)         # set seeds\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)  # make sure output dir exists\n",
        "print(\"Outputs will be saved to:\", cfg.out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbkm5L468UTm",
        "outputId": "2ba0194e-3415-4599-ab19-8c41498c1f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Outputs will be saved to: /content/drive/MyDrive/semeval_taskA_outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Normalize language spellings to the set we expect ====\n",
        "def normalize_language(s: str) -> str:\n",
        "    if s is None:\n",
        "        return \"unknown\"                # fallback if missing\n",
        "    t = str(s).strip().lower()          # canonicalize case/whitespace\n",
        "    # common aliases\n",
        "    if t in {\"py\", \"py3\", \"python3\"}: t = \"python\"\n",
        "    if t in {\"c++\", \"cpp\"}: t = \"cpp\"\n",
        "    if t in {\"c#\", \"cs\", \"csharp\"}: t = \"csharp\"\n",
        "    if t in {\"js\", \"javascript\", \"node\"}: t = \"javascript\"\n",
        "    if t in {\"golang\", \"go\"}: t = \"go\"\n",
        "    if t in {\"c\"}: t = \"c\"\n",
        "    if t in {\"java\"}: t = \"java\"\n",
        "    if t in {\"php\"}: t = \"php\"\n",
        "    return t\n",
        "\n",
        "# ==== Read parquet with expected columns and inject domain if absent ====\n",
        "def read_parquet_expect_cols(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_parquet(path)                         # load parquet -> DataFrame\n",
        "    required = {\"code\", \"generator\", \"label\", \"language\"}  # minimal set we rely on\n",
        "    missing = required - set(df.columns)               # check columns\n",
        "    if missing:\n",
        "        raise ValueError(f\"{path} missing required columns: {missing}\")\n",
        "\n",
        "    df = df.copy()                                     # avoid mutating the original\n",
        "    df[\"language\"] = df[\"language\"].apply(normalize_language)  # normalize language\n",
        "    if \"domain\" not in df.columns:                     # many task A files lack 'domain'\n",
        "        df[\"domain\"] = \"algorithmic\"                   # set default training domain\n",
        "    df[\"code\"] = df[\"code\"].astype(str)                # ensure code is string\n",
        "    return df\n",
        "\n",
        "# ==== Map label to explicit binary 0/1 (0=human, 1=machine) ====\n",
        "def map_labels_to_binary(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if np.issubdtype(df[\"label\"].dtype, np.number):    # numeric labels present\n",
        "        df[\"label_bin\"] = df[\"label\"].astype(int)      # coerce to int\n",
        "        uniq = set(df[\"label_bin\"].unique().tolist())  # check only {0,1}\n",
        "        if not uniq.issubset({0, 1}):\n",
        "            raise ValueError(f\"Numeric labels must be 0/1; found {uniq}\")\n",
        "        return df\n",
        "    # textual labels\n",
        "    def to_bin(x):\n",
        "        s = str(x).strip().lower()\n",
        "        if s in {\"0\", \"human\"}: return 0\n",
        "        if s in {\"1\", \"machine\", \"ai\", \"generated\", \"llm\"}: return 1\n",
        "        raise ValueError(f\"Unexpected label: {x}\")\n",
        "    df[\"label_bin\"] = df[\"label\"].apply(to_bin)\n",
        "    return df"
      ],
      "metadata": {
        "id": "dLWnJEHx9Ymd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== PyTorch Dataset that tokenizes on-the-fly ====\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_length: int):\n",
        "        self.df = df.reset_index(drop=True)       # clean 0..N-1 indexing\n",
        "        self.tok = tokenizer                      # HF tokenizer to encode text\n",
        "        self.max_length = max_length              # truncation length\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)                       # number of samples\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]                   # get row\n",
        "        code = row[\"code\"]                        # raw code text\n",
        "        label = int(row[\"label_bin\"])             # binary label 0/1\n",
        "        lang = row[\"language\"]                    # meta: language\n",
        "        dom  = row[\"domain\"]                      # meta: domain (default algorithmic)\n",
        "\n",
        "        prefix = f\"<lang:{lang}>\\n\"               # tiny hint for encoder (language tag)\n",
        "        text = prefix + code                      # prepend and concatenate\n",
        "\n",
        "        enc = self.tok(                           # tokenize with truncation + fixed padding\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),       # [seq_len]\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),  # [seq_len]\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),  # scalar label\n",
        "            \"language\": lang,                                # pass-through meta\n",
        "            \"domain\": dom                                    # pass-through meta\n",
        "        }\n",
        "        return item\n",
        "\n",
        "# ==== Build DataLoaders for train/val/test ====\n",
        "def build_loaders(cfg):\n",
        "    tok = AutoTokenizer.from_pretrained(cfg.model_name)  # load tokenizer that matches encoder\n",
        "\n",
        "    # read + normalize parquet\n",
        "    train_df = read_parquet_expect_cols(cfg.train_parquet)\n",
        "    val_df   = read_parquet_expect_cols(cfg.val_parquet)\n",
        "    train_df = map_labels_to_binary(train_df)\n",
        "    val_df   = map_labels_to_binary(val_df)\n",
        "\n",
        "    # optional test parquet (for generating probs)\n",
        "    test_df = None\n",
        "    if os.path.exists(cfg.test_parquet):\n",
        "        test_df = read_parquet_expect_cols(cfg.test_parquet)\n",
        "        if \"label\" in test_df.columns:\n",
        "            try:\n",
        "                test_df = map_labels_to_binary(test_df)  # if labels exist; else fallback\n",
        "            except Exception:\n",
        "                test_df[\"label_bin\"] = 0                 # placeholder not used\n",
        "        else:\n",
        "            test_df[\"label_bin\"] = 0\n",
        "\n",
        "    # create datasets\n",
        "    train_ds = CodeDataset(train_df, tok, cfg.max_length)\n",
        "    val_ds   = CodeDataset(val_df,   tok, cfg.max_length)\n",
        "    test_ds  = CodeDataset(test_df,  tok, cfg.max_length) if test_df is not None else None\n",
        "\n",
        "    # create loaders; Colab-friendly worker count; pin_memory for faster H2D\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.train_batch_size, shuffle=True,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=cfg.eval_batch_size,  shuffle=False,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=cfg.eval_batch_size,  shuffle=False,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True) if test_ds is not None else None\n",
        "\n",
        "    return tok, train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "wKocBrS-9afu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Simple binary classifier with CodeBERT encoder ====\n",
        "class CodeBERTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str):\n",
        "        super().__init__()                                          # init base class\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)        # load pretrained encoder\n",
        "        hidden = self.encoder.config.hidden_size                    # e.g., 768\n",
        "        self.drop = nn.Dropout(0.1)                                 # light regularization\n",
        "        self.cls  = nn.Linear(hidden, 1)                            # 1 logit (binary)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)  # encoder forward\n",
        "        cls_vec = out.last_hidden_state[:, 0, :]                                  # take [CLS]-like token\n",
        "        x = self.drop(cls_vec)                                                    # dropout\n",
        "        logits = self.cls(x).squeeze(-1)                                          # [B] logits\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qo8lzvyF9ccf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== overall metrics ====\n",
        "def compute_metrics(y_true: List[int], y_prob: List[float]) -> Dict[str, float]:\n",
        "    y_true = np.asarray(y_true).astype(int)       # ground-truth labels\n",
        "    y_prob = np.asarray(y_prob).astype(float)     # prob of class \"machine\" (1)\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, y_prob)     # AUROC\n",
        "    except ValueError:\n",
        "        auroc = float(\"nan\")                      # undefined if only one class\n",
        "    auprc = average_precision_score(y_true, y_prob)  # area under PR curve\n",
        "    y_pred = (y_prob >= 0.5).astype(int)          # simple 0.5 threshold\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\")# macro-F1\n",
        "    return {\"auroc\": auroc, \"auprc\": auprc, \"macro_f1\": f1}\n",
        "\n",
        "# ==== per-setting metrics (i)–(iv) using language & domain ====\n",
        "def compute_setting_metrics(meta: List[Tuple[str, str]], y_true: List[int], y_prob: List[float], cfg) -> Dict[str, Dict[str, float]]:\n",
        "    metas = np.array(meta)                        # shape [N, 2] of (lang, dom)\n",
        "    langs = metas[:, 0]\n",
        "    doms  = metas[:, 1]\n",
        "\n",
        "    def mask(seen_lang: bool, seen_dom: bool):\n",
        "        lm = np.isin(langs, cfg.seen_languages) if seen_lang else np.isin(langs, cfg.unseen_languages)\n",
        "        dm = np.isin(doms,  cfg.seen_domains)   if seen_dom  else np.isin(doms,  cfg.unseen_domains)\n",
        "        return lm & dm\n",
        "\n",
        "    masks = {\n",
        "        \"i\":   mask(True,  True),\n",
        "        \"ii\":  mask(False, True),\n",
        "        \"iii\": mask(True,  False),\n",
        "        \"iv\":  mask(False, False),\n",
        "    }\n",
        "\n",
        "    res = {}\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    for k, m in masks.items():\n",
        "        if m.sum() == 0:\n",
        "            res[k] = {\"auroc\": float(\"nan\"), \"auprc\": float(\"nan\"), \"macro_f1\": float(\"nan\")}\n",
        "        else:\n",
        "            res[k] = compute_metrics(y_true[m].tolist(), y_prob[m].tolist())\n",
        "    return res"
      ],
      "metadata": {
        "id": "wI25lDcw9eDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== one training epoch ====\n",
        "def train_one_epoch(model, loader, optimizer, scheduler, scaler, cfg):\n",
        "    model.train()                              # enable dropout etc.\n",
        "    total_loss, steps = 0.0, 0                 # track loss\n",
        "\n",
        "    # tqdm wrapper shows a progress bar\n",
        "    for i, batch in enumerate(tqdm(loader, desc=\"Training\", ncols=100)):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)     # H2D copy\n",
        "        attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        labels    = batch[\"label\"].float().to(device, non_blocking=True)\n",
        "\n",
        "        # mixed precision autocast (new API) speeds up training on GPU\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n",
        "            logits = model(input_ids=input_ids, attention_mask=attn)     # forward pass\n",
        "            loss   = nn.functional.binary_cross_entropy_with_logits(logits, labels)  # BCE-with-logits\n",
        "\n",
        "        # scale/backprop safely under AMP\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "        else:\n",
        "            loss.backward()\n",
        "\n",
        "        # gradient accumulation support\n",
        "        if (i + 1) % cfg.gradient_accumulation_steps == 0:\n",
        "            if scaler is not None:\n",
        "                scaler.unscale_(optimizer)                                 # unscale before clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)   # clip\n",
        "\n",
        "            if scaler is not None:\n",
        "                scaler.step(optimizer)                                     # optimizer step\n",
        "                scaler.update()                                            # update scaler\n",
        "            else:\n",
        "                optimizer.step()\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)                          # clear grads\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()                                           # advance LR schedule\n",
        "\n",
        "        total_loss += loss.item()                                          # accumulate loss\n",
        "        steps += 1                                                         # step count\n",
        "\n",
        "    return total_loss / max(1, steps)                                      # mean loss for the epoch\n",
        "\n",
        "# ==== evaluation helper (no grad) ====\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg):\n",
        "    model.eval()                                   # eval mode (no dropout)\n",
        "    probs, labels, metas = [], [], []              # accumulators\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Validating\", ncols=100):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "        attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        logits    = model(input_ids=input_ids, attention_mask=attn)        # forward\n",
        "        p         = torch.sigmoid(logits).detach().cpu().numpy().tolist()  # logits -> probs\n",
        "\n",
        "        probs.extend(p)                                                     # collect\n",
        "        labels.extend(batch[\"label\"].numpy().tolist())\n",
        "        metas.extend([(l, d) for l, d in zip(batch[\"language\"], batch[\"domain\"])])\n",
        "\n",
        "    overall  = compute_metrics(labels, probs)                               # overall metrics\n",
        "    settings = compute_setting_metrics(metas, labels, probs, cfg)           # per-setting metrics\n",
        "    return overall, settings, (labels, probs, metas)                        # return preds too for CSV dump\n",
        "\n",
        "# ==== full fit routine ====\n",
        "def fit_and_save(cfg):\n",
        "    # build loaders & tokenizer\n",
        "    tok, train_loader, val_loader, test_loader = build_loaders(cfg)\n",
        "\n",
        "    # init model and move to device\n",
        "    model = CodeBERTBinaryClassifier(cfg.model_name).to(device)\n",
        "\n",
        "    # optimizer / scheduler\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    total_steps = (len(train_loader) * cfg.epochs) // max(1, cfg.gradient_accumulation_steps)  # total optimizer steps\n",
        "    warmup_steps = int(cfg.warmup_ratio * total_steps)                                        # warmup proportion\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    # AMP scaler for CUDA; None on CPU\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "\n",
        "    best_f1 = -1.0                            # track best macro-F1\n",
        "    best_state = None                         # store best weights (CPU copy)\n",
        "\n",
        "    # training epochs\n",
        "    for ep in range(1, cfg.epochs + 1):\n",
        "        print(f\"\\n===== Epoch {ep}/{cfg.epochs} =====\")\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, cfg)   # train\n",
        "        overall, settings, _ = evaluate(model, val_loader, cfg)                                # validate\n",
        "\n",
        "        # log metrics\n",
        "        print(f\"\\nTrain loss: {train_loss:.4f}\")\n",
        "        print(f\"Val overall: AUROC={overall['auroc']:.4f}  AUPRC={overall['auprc']:.4f}  Macro-F1={overall['macro_f1']:.4f}\")\n",
        "        print(\"Val settings:\")\n",
        "        for k in [\"i\", \"ii\", \"iii\", \"iv\"]:\n",
        "            m = settings[k]\n",
        "            print(f\"  ({k})  AUROC={m['auroc']:.4f}  AUPRC={m['auprc']:.4f}  Macro-F1={m['macro_f1']:.4f}\")\n",
        "\n",
        "        # track & store best state dict by macro-F1\n",
        "        if overall[\"macro_f1\"] > best_f1:\n",
        "            best_f1 = overall[\"macro_f1\"]\n",
        "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
        "            print(f\"** New best Macro-F1 = {best_f1:.4f} (checkpoint cached in memory) **\")\n",
        "\n",
        "    # restore best weights before final eval / inference\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "        model.to(device)\n",
        "        # save to Drive\n",
        "        ckpt_path = os.path.join(cfg.out_dir, cfg.ckpt_name)\n",
        "        torch.save(best_state, ckpt_path)\n",
        "        print(f\"\\nSaved best checkpoint to: {ckpt_path}\")\n",
        "\n",
        "    # final val evaluation with best model, plus CSV dump for error analysis\n",
        "    final_overall, final_settings, (v_labels, v_probs, v_metas) = evaluate(model, val_loader, cfg)\n",
        "    print(\"\\n=== Final Validation (best) ===\")\n",
        "    print(f\"Overall: AUROC={final_overall['auroc']:.4f}  AUPRC={final_overall['auprc']:.4f}  Macro-F1={final_overall['macro_f1']:.4f}\")\n",
        "    print(\"Settings:\")\n",
        "    for k in [\"i\", \"ii\", \"iii\", \"iv\"]:\n",
        "        m = final_settings[k]\n",
        "        print(f\"  ({k})  AUROC={m['auroc']:.4f}  AUPRC={m['auprc']:.4f}  Macro-F1={m['macro_f1']:.4f}\")\n",
        "\n",
        "    # write validation predictions CSV\n",
        "    val_csv = os.path.join(cfg.out_dir, \"taskA_val_predictions.csv\")\n",
        "    v_langs = [x[0] for x in v_metas]\n",
        "    v_doms  = [x[1] for x in v_metas]\n",
        "    pd.DataFrame({\n",
        "        \"label\": v_labels,\n",
        "        \"prob_machine\": v_probs,\n",
        "        \"language\": v_langs,\n",
        "        \"domain\": v_doms\n",
        "    }).to_csv(val_csv, index=False)\n",
        "    print(f\"Wrote validation predictions to: {val_csv}\")\n",
        "\n",
        "    # optional: test-time predictions if test parquet exists\n",
        "    if os.path.exists(cfg.test_parquet):\n",
        "        model.eval()\n",
        "        test_probs, test_langs, test_doms = [], [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(test_loader, desc=\"Testing\", ncols=100):\n",
        "                input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "                attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "                logits    = model(input_ids=input_ids, attention_mask=attn)\n",
        "                p         = torch.sigmoid(logits).detach().cpu().numpy().tolist()\n",
        "                test_probs.extend(p)\n",
        "                test_langs.extend(list(batch[\"language\"]))\n",
        "                test_doms.extend(list(batch[\"domain\"]))\n",
        "        test_csv = os.path.join(cfg.out_dir, \"taskA_test_predictions.csv\")\n",
        "        pd.DataFrame({\n",
        "            \"prob_machine\": test_probs,\n",
        "            \"language\": test_langs,\n",
        "            \"domain\": test_doms\n",
        "        }).to_csv(test_csv, index=False)\n",
        "        print(f\"Wrote test probabilities to: {test_csv}\")"
      ],
      "metadata": {
        "id": "H1D-Q_ld9gch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kick off training + evaluation + saving\n",
        "fit_and_save(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d2b499ba196a407aad5e04f91a78870e",
            "cf95152577bd4c85a9daeaf03b9c4516",
            "beb49429b2a34a28be062e48bc599a1d",
            "0c5441e3d8dd4c6a920ceea5ff6c9867",
            "a8162a8c895d4d5cb8356c502472ce93",
            "c928d10f3fbd4be0bbd54ba1da9a14f2",
            "5e24dee1d0864d7292ffefd463b39a72",
            "007d442c7b5e4643ac9361c8f9cfa4a7",
            "b56b05c764824930ac339808ff5ea4c0",
            "2cc1d4a9f29d468d9b199fa837846903",
            "d8daec56ef39401892f0c769bc7a4b2a",
            "a6b71a94a5c24092964c874bf13b8600",
            "4e8432fcfcc440cab026f3aaea7393cd",
            "ac20e7d6460c4b84be722bf7c9961791",
            "693991a4d5724fea87d399b7b529e848",
            "bb76ed827ce441bdb3e1b962ac037d1b",
            "b8071685e9094f0fbf30e6f641333c81",
            "adeb07fd038943238b051e8977d51d9c",
            "9f4ba17f6cb9454a8912990b47c1f54f",
            "b6046351808c4c9181cda56362a3749d",
            "7ffdca8cc2ce4e50903803d21ed55a66",
            "9578e2826ec44bfba3991a8bfcb2796f",
            "fa03470d19154f18810bcd6fd90e4c10",
            "a9680f5f3c2e4f6e8d432b1eef131077",
            "a4afe0c911304e3eb5b71dc6625e6084",
            "f19aea02809f44d19ec1e055b00bdbab",
            "70fecdb0b38845f98c60f1c7c638ad85",
            "eb9cab6502254d768021cfde1deb3d88",
            "f13d5a3243c04d81b8f822dd5c615502",
            "aaeb052c4e29492ebf33d1fcd0680832",
            "eb146c7a53094214a0c50c468c647dcf",
            "170c4bdade0d4841b957dd2f946a27a0",
            "add6560fa9a146dcaa027307848cf9ea",
            "8561999e14cb4b7095e5d8991c031e8e",
            "808b7e8d08e84d628c28311da122954c",
            "c3312d79a8f941d2abaed2eed52fe576",
            "af31d1793eff471193d7bbd6ad6de5e7",
            "d7f89322675c4708b61854563f61e828",
            "815f3207790c4444ad164d682f65164e",
            "8e533e796c7c4c9a90f58d921841faaa",
            "63e51f6c1bc146fab929021bfd25d9ce",
            "be5102373ca24d16b921e127ccbc6aae",
            "c044d96b72d04550b5d989361786f64f",
            "33abe59f1ae84cbca32eadb022cf6b0c",
            "617317b31ec6498eb52afc669dd711b3",
            "a537e3c54e4943f3b04dfa5a9e79d013",
            "35a44908e1574545b192944fa40e3447",
            "97ed4c3a895f49cbabc8fd9b5094f6b7",
            "fb7f3b79893a4db28ce90f1f1ee733d6",
            "5f31b582b0014114b799575195ba999b",
            "55d211d15784457fbfb99414b4fc5a0f",
            "29baa43337a54c1484c6cb34a7cab820",
            "5ceee21a3da04f8aacbe26ca57f56a68",
            "151202297fd04a88a48e9afcd9ae1934",
            "4d30da4219464806b86892fd58f0229b",
            "47bc0b8b0dec4fcfba988047aefd05e5",
            "d1d5181ca0794eb0a734d3e81bf114b5",
            "4dcb2228532d419286d1647190ca2d16",
            "9c7bac4a9ae3459a87224128035d0924",
            "25422d3dfef340d1b22c78ad41397cf9",
            "d1a0a9aeb41b458392ca0b0e042004f1",
            "d19d0eb3d0cc4ad688df6d7f91252dfe",
            "23b57e7ecd804a1b8b5a1313f6039acc",
            "efe0728163a9462b92458041f305ceb6",
            "3fc2ef0db6844a89bcf74a5e9d32ba5d",
            "a5c72004a6a14487ba95af4730f2953e"
          ]
        },
        "id": "uEincYyO9mUs",
        "outputId": "d5a3dfe4-19a8-4e55-b8ab-671fb6ca3db1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2b499ba196a407aad5e04f91a78870e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6b71a94a5c24092964c874bf13b8600",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa03470d19154f18810bcd6fd90e4c10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8561999e14cb4b7095e5d8991c031e8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "617317b31ec6498eb52afc669dd711b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47bc0b8b0dec4fcfba988047aefd05e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2662754084.py:80: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Epoch 1/3 =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████████| 31250/31250 [47:29<00:00, 10.97it/s]\n",
            "Validating: 100%|███████████████████████████████████████████████| 3125/3125 [10:58<00:00,  4.75it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.0522\n",
            "Val overall: AUROC=0.9997  AUPRC=0.9997  Macro-F1=0.9919\n",
            "Val settings:\n",
            "  (i)  AUROC=0.9997  AUPRC=0.9997  Macro-F1=0.9919\n",
            "  (ii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iv)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "** New best Macro-F1 = 0.9919 (checkpoint cached in memory) **\n",
            "\n",
            "===== Epoch 2/3 =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|███████████████████████████████████████████████| 31250/31250 [47:21<00:00, 11.00it/s]\n",
            "Validating: 100%|███████████████████████████████████████████████| 3125/3125 [10:58<00:00,  4.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train loss: 0.0213\n",
            "Val overall: AUROC=0.9998  AUPRC=0.9998  Macro-F1=0.9944\n",
            "Val settings:\n",
            "  (i)  AUROC=0.9998  AUPRC=0.9998  Macro-F1=0.9944\n",
            "  (ii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iv)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "** New best Macro-F1 = 0.9944 (checkpoint cached in memory) **\n",
            "\n",
            "===== Epoch 3/3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|███████████████████████████████████████████████| 31250/31250 [47:21<00:00, 11.00it/s]\n",
            "Validating: 100%|███████████████████████████████████████████████| 3125/3125 [10:58<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train loss: 0.0137\n",
            "Val overall: AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952\n",
            "Val settings:\n",
            "  (i)  AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952\n",
            "  (ii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iv)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "** New best Macro-F1 = 0.9952 (checkpoint cached in memory) **\n",
            "\n",
            "Saved best checkpoint to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|███████████████████████████████████████████████| 3125/3125 [10:58<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Final Validation (best) ===\n",
            "Overall: AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952\n",
            "Settings:\n",
            "  (i)  AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952\n",
            "  (ii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iii)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "  (iv)  AUROC=nan  AUPRC=nan  Macro-F1=nan\n",
            "Wrote validation predictions to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_val_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████████████████████████████████████████████████| 32/32 [00:06<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote test probabilities to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_test_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true: List[int], y_prob: List[float]) -> Dict[str, float]:\n",
        "    import numpy as np\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
        "\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, y_prob)\n",
        "    except ValueError:\n",
        "        auroc = float(\"nan\")\n",
        "\n",
        "    auprc = average_precision_score(y_true, y_prob)\n",
        "\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return {\"auroc\": auroc, \"auprc\": auprc, \"macro_f1\": macro_f1, \"accuracy\": acc}"
      ],
      "metadata": {
        "id": "_foTA-lb9-m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_loaders(cfg):\n",
        "    tok = AutoTokenizer.from_pretrained(cfg.model_name)\n",
        "\n",
        "    train_df = read_parquet_expect_cols(cfg.train_parquet)\n",
        "    val_df   = read_parquet_expect_cols(cfg.val_parquet)\n",
        "    train_df = map_labels_to_binary(train_df)\n",
        "    val_df   = map_labels_to_binary(val_df)\n",
        "\n",
        "    test_df = None\n",
        "    test_has_labels = False\n",
        "    if os.path.exists(cfg.test_parquet):\n",
        "        test_df = read_parquet_expect_cols(cfg.test_parquet)\n",
        "        if \"label\" in test_df.columns:\n",
        "            test_df = map_labels_to_binary(test_df)\n",
        "            test_has_labels = True\n",
        "        else:\n",
        "            test_df = test_df.copy()\n",
        "            test_df[\"label_bin\"] = 0  # placeholder\n",
        "\n",
        "    train_ds = CodeDataset(train_df, tok, cfg.max_length)\n",
        "    val_ds   = CodeDataset(val_df,   tok, cfg.max_length)\n",
        "    test_ds  = CodeDataset(test_df,  tok, cfg.max_length) if test_df is not None else None\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.train_batch_size, shuffle=True,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=cfg.eval_batch_size,  shuffle=False,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=cfg.eval_batch_size,  shuffle=False,\n",
        "                              num_workers=cfg.num_workers, pin_memory=True) if test_ds is not None else None\n",
        "\n",
        "    # return tokenizer too if you need it elsewhere\n",
        "    return tok, train_loader, val_loader, test_loader, test_has_labels"
      ],
      "metadata": {
        "id": "zUteG1ik_j5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Evaluation-only script: reload best checkpoint, compute metrics, and write CSVs =====\n",
        "\n",
        "# 0) Environment\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 1) Config — EDIT THESE PATHS if needed\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Your paths (you said these are your files)\n",
        "    train_parquet: str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_training_set_1.parquet\"\n",
        "    val_parquet: str   = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet\"\n",
        "    test_parquet: str  = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"  # labeled sample\n",
        "\n",
        "    # Must match the model used during training\n",
        "    model_name: str = \"microsoft/codebert-base\"\n",
        "\n",
        "    # Tokenization / loader\n",
        "    max_length: int = 512\n",
        "    eval_batch_size: int = 32\n",
        "    num_workers: int = 2\n",
        "\n",
        "    # Eval settings\n",
        "    seen_languages: Tuple[str, ...] = (\"cpp\", \"python\", \"java\")\n",
        "    unseen_languages: Tuple[str, ...] = (\"go\", \"php\", \"csharp\", \"c\", \"javascript\")\n",
        "    seen_domains: Tuple[str, ...] = (\"algorithmic\",)\n",
        "    unseen_domains: Tuple[str, ...] = (\"research\", \"production\")\n",
        "\n",
        "    # Outputs\n",
        "    out_dir: str = \"/content/drive/MyDrive/semeval_taskA_outputs\"\n",
        "    ckpt_name: str = \"taskA_codebert_best.pt\"\n",
        "\n",
        "cfg = Config()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "ckpt_path = os.path.join(cfg.out_dir, cfg.ckpt_name)\n",
        "print(\"Checkpoint path:\", ckpt_path)\n",
        "\n",
        "# 2) Helpers: language normalization & parquet readers\n",
        "def normalize_language(s: str) -> str:\n",
        "    if s is None:\n",
        "        return \"unknown\"\n",
        "    t = str(s).strip().lower()\n",
        "    if t in {\"py\", \"py3\", \"python3\"}: t = \"python\"\n",
        "    if t in {\"c++\", \"cpp\"}: t = \"cpp\"\n",
        "    if t in {\"c#\", \"cs\", \"csharp\"}: t = \"csharp\"\n",
        "    if t in {\"js\", \"javascript\", \"node\"}: t = \"javascript\"\n",
        "    if t in {\"golang\", \"go\"}: t = \"go\"\n",
        "    if t in {\"c\"}: t = \"c\"\n",
        "    if t in {\"java\"}: t = \"java\"\n",
        "    if t in {\"php\"}: t = \"php\"\n",
        "    return t\n",
        "\n",
        "def read_parquet_expect_cols(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_parquet(path)\n",
        "    required = {\"code\", \"generator\", \"label\", \"language\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{path} missing required columns: {missing}\")\n",
        "    df = df.copy()\n",
        "    df[\"language\"] = df[\"language\"].apply(normalize_language)\n",
        "    if \"domain\" not in df.columns:\n",
        "        df[\"domain\"] = \"algorithmic\"\n",
        "    df[\"code\"] = df[\"code\"].astype(str)\n",
        "    return df\n",
        "\n",
        "def map_labels_to_binary(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if np.issubdtype(df[\"label\"].dtype, np.number):\n",
        "        df[\"label_bin\"] = df[\"label\"].astype(int)\n",
        "        uniq = set(df[\"label_bin\"].unique().tolist())\n",
        "        if not uniq.issubset({0, 1}):\n",
        "            raise ValueError(f\"Numeric labels must be 0/1; found {uniq}\")\n",
        "        return df\n",
        "    def to_bin(x):\n",
        "        s = str(x).strip().lower()\n",
        "        if s in {\"0\", \"human\"}: return 0\n",
        "        if s in {\"1\", \"machine\", \"ai\", \"generated\", \"llm\"}: return 1\n",
        "        raise ValueError(f\"Unexpected label: {x}\")\n",
        "    df[\"label_bin\"] = df[\"label\"].apply(to_bin)\n",
        "    return df\n",
        "\n",
        "# 3) Dataset / DataLoaders\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer: AutoTokenizer, max_length: int):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        code = row[\"code\"]\n",
        "        label = int(row[\"label_bin\"])\n",
        "        lang = row[\"language\"]\n",
        "        dom  = row[\"domain\"]\n",
        "        prefix = f\"<lang:{lang}>\\n\"\n",
        "        text = prefix + code\n",
        "        enc = self.tok(text, max_length=self.max_length, padding=\"max_length\",\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "            \"language\": lang,\n",
        "            \"domain\": dom,\n",
        "        }\n",
        "\n",
        "def build_loaders(cfg):\n",
        "    tok = AutoTokenizer.from_pretrained(cfg.model_name)\n",
        "\n",
        "    val_df = read_parquet_expect_cols(cfg.val_parquet)\n",
        "    val_df = map_labels_to_binary(val_df)\n",
        "\n",
        "    test_df, test_has_labels = None, False\n",
        "    if os.path.exists(cfg.test_parquet):\n",
        "        test_df = read_parquet_expect_cols(cfg.test_parquet)\n",
        "        if \"label\" in test_df.columns:\n",
        "            test_df = map_labels_to_binary(test_df)\n",
        "            test_has_labels = True\n",
        "        else:\n",
        "            test_df = test_df.copy()\n",
        "            test_df[\"label_bin\"] = 0\n",
        "\n",
        "    val_ds  = CodeDataset(val_df, tok, cfg.max_length)\n",
        "    test_ds = CodeDataset(test_df, tok, cfg.max_length) if test_df is not None else None\n",
        "\n",
        "    val_loader  = DataLoader(val_ds,  batch_size=cfg.eval_batch_size, shuffle=False,\n",
        "                             num_workers=cfg.num_workers, pin_memory=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=cfg.eval_batch_size, shuffle=False,\n",
        "                             num_workers=cfg.num_workers, pin_memory=True) if test_ds is not None else None\n",
        "    return tok, val_loader, test_loader, test_has_labels\n",
        "\n",
        "# 4) Model\n",
        "class CodeBERTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        h = self.encoder.config.hidden_size\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.cls  = nn.Linear(h, 1)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_vec = out.last_hidden_state[:, 0, :]\n",
        "        return self.cls(self.drop(cls_vec)).squeeze(-1)\n",
        "\n",
        "# 5) Metrics\n",
        "def compute_metrics(y_true: List[int], y_prob: List[float]) -> Dict[str, float]:\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, y_prob)\n",
        "    except ValueError:\n",
        "        auroc = float(\"nan\")\n",
        "    auprc = average_precision_score(y_true, y_prob)\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    return {\"auroc\": auroc, \"auprc\": auprc, \"macro_f1\": macro_f1, \"accuracy\": acc}\n",
        "\n",
        "def compute_setting_metrics(meta: List[Tuple[str, str]], y_true: List[int], y_prob: List[float], cfg) -> Dict[str, Dict[str, float]]:\n",
        "    metas = np.array(meta)\n",
        "    langs = metas[:, 0]\n",
        "    doms  = metas[:, 1]\n",
        "    def mask(seen_lang: bool, seen_dom: bool):\n",
        "        lm = np.isin(langs, cfg.seen_languages) if seen_lang else np.isin(langs, cfg.unseen_languages)\n",
        "        dm = np.isin(doms,  cfg.seen_domains)   if seen_dom  else np.isin(doms,  cfg.unseen_domains)\n",
        "        return lm & dm\n",
        "    masks = {\"i\": mask(True, True), \"ii\": mask(False, True), \"iii\": mask(True, False), \"iv\": mask(False, False)}\n",
        "    res = {}\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    for k, m in masks.items():\n",
        "        if m.sum() == 0:\n",
        "            res[k] = {\"auroc\": float(\"nan\"), \"auprc\": float(\"nan\"), \"macro_f1\": float(\"nan\"), \"accuracy\": float(\"nan\")}\n",
        "        else:\n",
        "            res[k] = compute_metrics(y_true[m].tolist(), y_prob[m].tolist())\n",
        "    return res\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, cfg):\n",
        "    model.eval()\n",
        "    probs, labels, metas = [], [], []\n",
        "    for batch in tqdm(loader, desc=\"Evaluating\", ncols=100):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "        attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        logits    = model(input_ids=input_ids, attention_mask=attn)\n",
        "        p         = torch.sigmoid(logits).detach().cpu().numpy().tolist()\n",
        "        probs.extend(p)\n",
        "        labels.extend(batch[\"label\"].numpy().tolist())\n",
        "        metas.extend([(l, d) for l, d in zip(batch[\"language\"], batch[\"domain\"])])\n",
        "    overall  = compute_metrics(labels, probs)\n",
        "    settings = compute_setting_metrics(metas, labels, probs, cfg)\n",
        "    return overall, settings, (labels, probs, metas)\n",
        "\n",
        "# 6) Reload checkpoint and evaluate\n",
        "# Build loaders\n",
        "tok, val_loader, test_loader, test_has_labels = build_loaders(cfg)\n",
        "\n",
        "# Rebuild the model and load the saved weights\n",
        "model = CodeBERTBinaryClassifier(cfg.model_name)\n",
        "assert os.path.exists(ckpt_path), f\"Checkpoint not found at {ckpt_path}\"\n",
        "state = torch.load(ckpt_path, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"✅ Loaded checkpoint from: {ckpt_path}\")\n",
        "\n",
        "# Validation evaluation\n",
        "val_overall, val_settings, (v_labels, v_probs, v_metas) = evaluate(model, val_loader, cfg)\n",
        "print(\"\\n=== Validation Metrics (reloaded) ===\")\n",
        "print(f\"Overall → AUROC={val_overall['auroc']:.4f}  AUPRC={val_overall['auprc']:.4f}  \"\n",
        "      f\"Macro-F1={val_overall['macro_f1']:.4f}  Accuracy={val_overall['accuracy']:.4f}\")\n",
        "for k in [\"i\", \"ii\", \"iii\", \"iv\"]:\n",
        "    m = val_settings[k]\n",
        "    print(f\"({k}) → AUROC={m['auroc']:.4f}  AUPRC={m['auprc']:.4f}  Macro-F1={m['macro_f1']:.4f}  Accuracy={m['accuracy']:.4f}\")\n",
        "\n",
        "# Write validation predictions CSV\n",
        "v_langs = [x[0] for x in v_metas]\n",
        "v_doms  = [x[1] for x in v_metas]\n",
        "val_csv = os.path.join(cfg.out_dir, \"taskA_val_predictions.csv\")\n",
        "pd.DataFrame({\"label\": v_labels, \"prob_machine\": v_probs, \"language\": v_langs, \"domain\": v_doms}).to_csv(val_csv, index=False)\n",
        "print(f\"Wrote validation predictions to: {val_csv}\")\n",
        "\n",
        "# Test evaluation (since your sample test set has labels)\n",
        "if (test_loader is not None) and test_has_labels:\n",
        "    test_overall, test_settings, (t_labels, t_probs, t_metas) = evaluate(model, test_loader, cfg)\n",
        "    print(\"\\n=== Test Metrics (reloaded) ===\")\n",
        "    print(f\"Overall → AUROC={test_overall['auroc']:.4f}  AUPRC={test_overall['auprc']:.4f}  \"\n",
        "          f\"Macro-F1={test_overall['macro_f1']:.4f}  Accuracy={test_overall['accuracy']:.4f}\")\n",
        "    for k in [\"i\", \"ii\", \"iii\", \"iv\"]:\n",
        "        tm = test_settings[k]\n",
        "        print(f\"({k}) → AUROC={tm['auroc']:.4f}  AUPRC={tm['auprc']:.4f}  Macro-F1={tm['macro_f1']:.4f}  Accuracy={tm['accuracy']:.4f}\")\n",
        "\n",
        "    # Write labeled test CSV for analysis\n",
        "    t_langs = [x[0] for x in t_metas]\n",
        "    t_doms  = [x[1] for x in t_metas]\n",
        "    test_csv = os.path.join(cfg.out_dir, \"taskA_test_predictions_labeled.csv\")\n",
        "    pd.DataFrame({\"label\": t_labels, \"prob_machine\": t_probs, \"language\": t_langs, \"domain\": t_doms}).to_csv(test_csv, index=False)\n",
        "    print(f\"Wrote labeled test predictions to: {test_csv}\")\n",
        "\n",
        "elif test_loader is not None:\n",
        "    # If you ever have an unlabeled test, you can still dump probabilities\n",
        "    test_probs, test_langs, test_doms = [], [], []\n",
        "    for batch in tqdm(test_loader, desc=\"Predicting (unlabeled test)\", ncols=100):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "        attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        p = torch.sigmoid(model(input_ids=input_ids, attention_mask=attn)).detach().cpu().numpy().tolist()\n",
        "        test_probs.extend(p)\n",
        "        test_langs.extend(list(batch[\"language\"]))\n",
        "        test_doms.extend(list(batch[\"domain\"]))\n",
        "    test_csv = os.path.join(cfg.out_dir, \"taskA_test_predictions.csv\")\n",
        "    pd.DataFrame({\"prob_machine\": test_probs, \"language\": test_langs, \"domain\": test_doms}).to_csv(test_csv, index=False)\n",
        "    print(f\"Wrote test probabilities to: {test_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6T6J7suSmv0",
        "outputId": "f424ec21-2f05-476a-b832-2a0e6bdcde74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Checkpoint path: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded checkpoint from: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|███████████████████████████████████████████████| 3125/3125 [10:58<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Validation Metrics (reloaded) ===\n",
            "Overall → AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952  Accuracy=0.9952\n",
            "(i) → AUROC=0.9999  AUPRC=0.9998  Macro-F1=0.9952  Accuracy=0.9952\n",
            "(ii) → AUROC=nan  AUPRC=nan  Macro-F1=nan  Accuracy=nan\n",
            "(iii) → AUROC=nan  AUPRC=nan  Macro-F1=nan  Accuracy=nan\n",
            "(iv) → AUROC=nan  AUPRC=nan  Macro-F1=nan  Accuracy=nan\n",
            "Wrote validation predictions to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_val_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|███████████████████████████████████████████████████| 32/32 [00:06<00:00,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test Metrics (reloaded) ===\n",
            "Overall → AUROC=0.4080  AUPRC=0.1847  Macro-F1=0.2531  Accuracy=0.2600\n",
            "(i) → AUROC=0.4406  AUPRC=0.1809  Macro-F1=0.2934  Accuracy=0.2965\n",
            "(ii) → AUROC=0.3459  AUPRC=0.1978  Macro-F1=0.1788  Accuracy=0.1967\n",
            "(iii) → AUROC=nan  AUPRC=nan  Macro-F1=nan  Accuracy=nan\n",
            "(iv) → AUROC=nan  AUPRC=nan  Macro-F1=nan  Accuracy=nan\n",
            "Wrote labeled test predictions to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_test_predictions_labeled.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Add predictions to the test parquet, preserving the original 4 columns ===\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- Config (edit paths if needed) ---\n",
        "@dataclass\n",
        "class Config:\n",
        "    test_parquet: str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"\n",
        "    model_name:  str  = \"microsoft/codebert-base\"\n",
        "    ckpt_path:   str  = \"/content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\"\n",
        "    out_dir:     str  = \"/content/drive/MyDrive/semeval_taskA_outputs\"\n",
        "    max_length:  int  = 512\n",
        "    batch_size:  int  = 32\n",
        "    num_workers: int  = 2\n",
        "    threshold:   float = 0.5  # decision boundary for predicted label\n",
        "\n",
        "cfg = Config()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "\n",
        "# --- Tiny helpers ---\n",
        "def normalize_language(s: str) -> str:\n",
        "    t = str(s).strip().lower()\n",
        "    if t in {\"py\",\"py3\",\"python3\"}: t=\"python\"\n",
        "    if t in {\"c++\",\"cpp\"}: t=\"cpp\"\n",
        "    if t in {\"c#\",\"cs\",\"csharp\"}: t=\"csharp\"\n",
        "    if t in {\"js\",\"javascript\",\"node\"}: t=\"javascript\"\n",
        "    if t in {\"golang\",\"go\"}: t=\"go\"\n",
        "    return t\n",
        "\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tok: AutoTokenizer, max_length: int):\n",
        "        self.df = df.reset_index(drop=False)  # keep original row index in 'index'\n",
        "        self.tok = tok\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i: int):\n",
        "        row = self.df.iloc[i]\n",
        "        code = str(row[\"code\"])\n",
        "        lang = normalize_language(row[\"language\"])\n",
        "        text = f\"<lang:{lang}>\\n\" + code\n",
        "        enc = self.tok(text, max_length=self.max_length, padding=\"max_length\",\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"index\": int(row[\"index\"]),  # original row order\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"language_norm\": lang,\n",
        "        }\n",
        "\n",
        "# --- Load test parquet exactly as-is (we won’t modify its columns) ---\n",
        "df_raw = pd.read_parquet(cfg.test_parquet)\n",
        "assert {\"code\",\"generator\",\"label\",\"language\"}.issubset(df_raw.columns), \"Test parquet must have 4 columns.\"\n",
        "\n",
        "# --- Build tokenizer, dataset, loader (tokenization uses normalized lang; output keeps originals) ---\n",
        "tok = AutoTokenizer.from_pretrained(cfg.model_name)\n",
        "test_ds = CodeDataset(df_raw, tok, cfg.max_length)\n",
        "test_loader = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False,\n",
        "                         num_workers=cfg.num_workers, pin_memory=True)\n",
        "\n",
        "# --- Rebuild model and load checkpoint ---\n",
        "class CodeBERTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        h = self.encoder.config.hidden_size\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.cls  = nn.Linear(h, 1)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_vec = out.last_hidden_state[:,0,:]\n",
        "        return self.cls(self.drop(cls_vec)).squeeze(-1)\n",
        "\n",
        "model = CodeBERTBinaryClassifier(cfg.model_name)\n",
        "state = torch.load(cfg.ckpt_path, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(f\"✅ Loaded checkpoint: {cfg.ckpt_path}\")\n",
        "\n",
        "# --- Inference to collect probabilities in original order ---\n",
        "probs = np.zeros(len(df_raw), dtype=np.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Scoring test\", ncols=100):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "        attn      = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        logits    = model(input_ids=input_ids, attention_mask=attn)\n",
        "        p         = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "        idxs      = batch[\"index\"].numpy()\n",
        "        probs[idxs] = p  # place back into original row positions\n",
        "\n",
        "# --- Create predicted labels matching the original label format ---\n",
        "# If original test labels are numeric {0,1}, keep numeric; if textual, keep \"human\"/\"machine\"\n",
        "labels = df_raw[\"label\"]\n",
        "if np.issubdtype(labels.dtype, np.number):\n",
        "    pred_label = (probs >= cfg.threshold).astype(int)\n",
        "else:\n",
        "    pred_label = np.where(probs >= cfg.threshold, \"machine\", \"human\")\n",
        "\n",
        "# --- Build the output DataFrame: original 4 columns + predictions ---\n",
        "out = df_raw.copy()  # preserves original columns as-is\n",
        "out[\"prob_machine\"] = probs\n",
        "out[\"pred_label\"]   = pred_label  # same encoding style as original 'label'\n",
        "\n",
        "# --- Save CSV and Parquet ---\n",
        "csv_path = os.path.join(cfg.out_dir, \"taskA_test_with_predictions.csv\")\n",
        "pq_path  = os.path.join(cfg.out_dir, \"taskA_test_with_predictions.parquet\")\n",
        "out.to_csv(csv_path, index=False)\n",
        "out.to_parquet(pq_path, index=False)\n",
        "print(f\"Saved:\\n- {csv_path}\\n- {pq_path}\")\n",
        "\n",
        "# (Optional) quick peek at head/tail counts\n",
        "print(\"\\nHead:\")\n",
        "display(out.head(3))\n",
        "print(\"\\nLabel distribution vs Predicted distribution:\")\n",
        "print(\"labels:\\n\", pd.Series(labels).value_counts())\n",
        "print(\"pred_label:\\n\", pd.Series(out['pred_label']).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "0ZxOIc-ZSzlj",
        "outputId": "0a6c0f81-6c40-4aa8-9f6a-8987fdfd74a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded checkpoint: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring test: 100%|█████████████████████████████████████████████████| 32/32 [00:06<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "- /content/drive/MyDrive/semeval_taskA_outputs/taskA_test_with_predictions.csv\n",
            "- /content/drive/MyDrive/semeval_taskA_outputs/taskA_test_with_predictions.parquet\n",
            "\n",
            "Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                code generator  label  \\\n",
              "0  public Vector To(Vector o)\\n        {\\n       ...     Human      0   \n",
              "1  func (v *DefaultMessageSyntaxValidator) Valida...     Human      0   \n",
              "2  \"\"\"Module managing testsuite capabilities\\n\\nC...     Human      0   \n",
              "\n",
              "  language  prob_machine  pred_label  \n",
              "0       C#      0.999973           1  \n",
              "1       Go      0.999967           1  \n",
              "2   Python      0.998837           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6914dcaa-b7a5-4f34-9578-51b53501315b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>generator</th>\n",
              "      <th>label</th>\n",
              "      <th>language</th>\n",
              "      <th>prob_machine</th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>public Vector To(Vector o)\\n        {\\n       ...</td>\n",
              "      <td>Human</td>\n",
              "      <td>0</td>\n",
              "      <td>C#</td>\n",
              "      <td>0.999973</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>func (v *DefaultMessageSyntaxValidator) Valida...</td>\n",
              "      <td>Human</td>\n",
              "      <td>0</td>\n",
              "      <td>Go</td>\n",
              "      <td>0.999967</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"\"\"Module managing testsuite capabilities\\n\\nC...</td>\n",
              "      <td>Human</td>\n",
              "      <td>0</td>\n",
              "      <td>Python</td>\n",
              "      <td>0.998837</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6914dcaa-b7a5-4f34-9578-51b53501315b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6914dcaa-b7a5-4f34-9578-51b53501315b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6914dcaa-b7a5-4f34-9578-51b53501315b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9b65f5f2-5d11-4b24-96a7-8be414800d06\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b65f5f2-5d11-4b24-96a7-8be414800d06')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9b65f5f2-5d11-4b24-96a7-8be414800d06 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"pred_label:\\\\n\\\", pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"public Vector To(Vector o)\\n        {\\n            Vector direction = Direction(this, o);\\n            X = direction.X;\\n            Y = direction.Y;\\n            Z = direction.Z;\\n            return this;\\n        }\",\n          \"func (v *DefaultMessageSyntaxValidator) ValidateUnsignedMessageSyntax(ctx context.Context, msg *types.UnsignedMessage) error {\\n\\tbuf := new(bytes.Buffer)\\n\\terr := msg.MarshalCBOR(buf)\\n\\tif err != nil {\\n\\t\\treturn errors.Wrapf(err, \\\"failed to calculate message size\\\")\\n\\t}\\n\\treturn v.validateMessageSyntaxShared(ctx, msg, int64(buf.Len()))\\n}\",\n          \"\\\"\\\"\\\"Module managing testsuite capabilities\\n\\nCapability is set of (usually) strings which tell us which features are available on this test environment.\\nIn tests you can use it with pytest.mark.require_capabilities(capability1, capability2, ...)\\n\\nCapabilities are provider by a functions annotated with @capability_provider and should return Set of capabilities\\n\\\"\\\"\\\"\\nimport enum\\nfrom typing import Set, Callable, Any, Tuple, List\\n\\n# Users should have access only to these public methods/decorators\\n__all__ = [\\\"CapabilityRegistry\\\", \\\"Capability\\\"]\\n\\n\\nclass Capability(enum.Enum):\\n    \\\"\\\"\\\"Enum containing all known environment capabilities\\\"\\\"\\\"\\n    PRODUCTION_GATEWAY = \\\"production\\\"           # Allows production gateway with reload() capability\\n    APICAST = \\\"apicast\\\"                         # Is APIcast, this is mutually exclusive with Service Mesh\\n    CUSTOM_ENVIRONMENT = \\\"env\\\"                  # Allows environment manipulation through environ() method\\n    SAME_CLUSTER = \\\"internal-cluster\\\"           # Is always located on the same cluster as 3scale\\n    SERVICE_MESH = \\\"service-mesh\\\"               # It is running through Service Mesh\\n    SERVICE_MESH_WASM = \\\"wasm\\\"                  # It is running through WASM extension with ServiceMesh 2.1\\n    SERVICE_MESH_ADAPTER = \\\"adapter\\\"            # It is running through Istio adapter with Service Mesh 2.0\\n    STANDARD_GATEWAY = \\\"standard\\\"               # Tests which deploy their own gateway will run\\n    LOGS = \\\"logs\\\"                               # Allows getting APIcast logs through get_logs() method\\n    JAEGER = \\\"jaeger\\\"                           # Allows configuring the APIcast to send data to Jaeger\\n    OCP4 = \\\"ocp4\\\"                               # If the current environment is OpenShift 4\\n    OCP3 = \\\"ocp3\\\"                               # If the current environment is OpenShift 3\\n    SCALING = \\\"scaling\\\"                         # If the current environment supports scaling of components\\n\\n\\nclass Singleton(type):\\n    \\\"\\\"\\\"Metaclass for creating Singletons\\\"\\\"\\\"\\n    def __init__(cls, name, bases, mmbs):\\n        super().__init__(name, bases, mmbs)\\n        cls._instance = super().__call__()\\n\\n    def __call__(cls, *args, **kw):\\n        return cls._instance\\n\\n\\nProvider = Callable[[], Set[Any]]\\n\\n\\nclass CapabilityRegistry(metaclass=Singleton):\\n    \\\"\\\"\\\"Registry for all the capabilities testsuite has\\\"\\\"\\\"\\n    def __init__(self) -> None:\\n        super().__init__()\\n        self.providers: List[Tuple[Set[Any], Provider]] = []\\n        self.discovered: Set[Any] = set()\\n        self.capabilities: Set[Any] = set()\\n\\n    def register_provider(self, provider: Provider, provides: Set[Any]):\\n        \\\"\\\"\\\"Register new capability provider\\\"\\\"\\\"\\n        self.providers.append((provides, provider))\\n\\n    def _find_provider(self, capability):\\n        \\\"\\\"\\\"\\n        Returns provider and all capabilities it can provide based on the capability requested\\n        Runs in O(n) due to discrepancy between discovered capabilities (=those whose providers have been run)\\n        and actual capabilities (=those that are present). Still faster than if all providers were run at all times.\\n        \\\"\\\"\\\"\\n        for capabilities, provider in self.providers:\\n            if capability in capabilities:\\n                return capabilities, provider\\n        return None\\n\\n    def __contains__(self, item):\\n        if item not in self.discovered:\\n            capabilities, provider = self._find_provider(item)\\n            if provider is None:\\n                # Capability is unknown and not provided by anyone\\n                return False\\n            new_capabilities = provider()\\n            self.discovered.update(capabilities)\\n            self.capabilities.update(new_capabilities)\\n        return item in self.capabilities\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Human\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C#\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_machine\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9999734163284302\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label distribution vs Predicted distribution:\n",
            "labels:\n",
            " label\n",
            "0    777\n",
            "1    223\n",
            "Name: count, dtype: int64\n",
            "pred_label:\n",
            " pred_label\n",
            "1    873\n",
            "0    127\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, pandas as pd, torch\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- Paths ---\n",
        "test_path = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"\n",
        "ckpt_path = \"/content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\"\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "\n",
        "# --- Load test data ---\n",
        "df_test = pd.read_parquet(test_path)\n",
        "assert {\"code\",\"generator\",\"label\",\"language\"}.issubset(df_test.columns)\n",
        "\n",
        "# --- Tokenizer ---\n",
        "tok = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# --- Model ---\n",
        "class CodeBERTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        h = self.encoder.config.hidden_size\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.cls = nn.Linear(h, 1)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_vec = out.last_hidden_state[:,0,:]\n",
        "        return self.cls(self.drop(cls_vec)).squeeze(-1)\n",
        "\n",
        "model = CodeBERTBinaryClassifier(model_name)\n",
        "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
        "model.to(device).eval()\n",
        "print(f\"✅ Loaded model from: {ckpt_path}\")\n",
        "\n",
        "# --- Dataset loader ---\n",
        "class CodeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tok, max_len=512):\n",
        "        self.df, self.tok, self.max_len = df.reset_index(drop=True), tok, max_len\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        text = f\"<lang:{row['language'].lower()}>\\n{row['code']}\"\n",
        "        enc = self.tok(text, max_length=self.max_len, padding=\"max_length\",\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "        return {\"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "                \"attention_mask\": enc[\"attention_mask\"].squeeze(0)}\n",
        "\n",
        "loader = torch.utils.data.DataLoader(CodeDataset(df_test, tok), batch_size=32, shuffle=False)\n",
        "\n",
        "# --- Inference ---\n",
        "probs = []\n",
        "with torch.no_grad():\n",
        "    for b in tqdm(loader, desc=\"Scoring test\", ncols=100):\n",
        "        ids = b[\"input_ids\"].to(device)\n",
        "        attn = b[\"attention_mask\"].to(device)\n",
        "        logits = model(ids, attn)\n",
        "        probs.extend(torch.sigmoid(logits).cpu().numpy())\n",
        "probs = np.array(probs)\n",
        "\n",
        "# --- Predicted labels (0/1) and true labels ---\n",
        "threshold = 0.5\n",
        "preds = (probs >= threshold).astype(int)\n",
        "\n",
        "# if labels are textual, convert to numeric\n",
        "y_true = df_test[\"label\"].apply(lambda x: 1 if str(x).lower() in {\"1\",\"machine\",\"ai\",\"llm\"} else 0).values\n",
        "\n",
        "# --- Metrics summary ---\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "acc = accuracy_score(y_true, preds)\n",
        "f1  = f1_score(y_true, preds, average=\"macro\")\n",
        "prec = precision_score(y_true, preds, average=\"macro\")\n",
        "rec  = recall_score(y_true, preds, average=\"macro\")\n",
        "\n",
        "print(\"\\n=== Summary Metrics ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Macro F1 : {f1:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "\n",
        "# --- Confusion matrix ---\n",
        "cm = confusion_matrix(y_true, preds)\n",
        "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax[0])\n",
        "ax[0].set_title(\"Confusion Matrix (raw)\")\n",
        "ax[0].set_xlabel(\"Predicted\")\n",
        "ax[0].set_ylabel(\"True\")\n",
        "\n",
        "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Greens\", cbar=False, ax=ax[1])\n",
        "ax[1].set_title(\"Confusion Matrix (normalized)\")\n",
        "ax[1].set_xlabel(\"Predicted\")\n",
        "ax[1].set_ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# --- Classification report ---\n",
        "print(\"\\n=== Detailed Classification Report ===\")\n",
        "print(classification_report(y_true, preds, target_names=[\"Human (0)\",\"Machine (1)\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "7EbU-i2eXt5v",
        "outputId": "8afec531-77cb-405e-fb9a-e067c2e608e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded model from: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring test: 100%|█████████████████████████████████████████████████| 32/32 [00:08<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Summary Metrics ===\n",
            "Accuracy : 0.2610\n",
            "Macro F1 : 0.2543\n",
            "Precision: 0.4263\n",
            "Recall   : 0.4525\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detailed Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Human (0)       0.65      0.11      0.18       777\n",
            " Machine (1)       0.20      0.80      0.33       223\n",
            "\n",
            "    accuracy                           0.26      1000\n",
            "   macro avg       0.43      0.45      0.25      1000\n",
            "weighted avg       0.55      0.26      0.22      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Inference-only: add identifier-renaming ensemble + per-language thresholds + orientation selection =====\n",
        "import os, re, gc, numpy as np, pandas as pd, torch\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics import (\n",
        "    f1_score, accuracy_score, precision_score, recall_score,\n",
        "    roc_auc_score, average_precision_score, confusion_matrix\n",
        ")\n",
        "\n",
        "# ---------------- Config (EDIT PATHS IF NEEDED) ----------------\n",
        "@dataclass\n",
        "class Cfg:\n",
        "    model_name: str = \"microsoft/codebert-base\"\n",
        "    ckpt_path: str = \"/content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\"\n",
        "\n",
        "    val_parquet:  str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet\"\n",
        "    test_parquet: str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"\n",
        "\n",
        "    out_dir: str = \"/content/drive/MyDrive/semeval_taskA_outputs\"\n",
        "    max_len: int = 512\n",
        "    batch_size: int = 32\n",
        "    num_workers: int = 2\n",
        "\n",
        "cfg = Cfg()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------------- Data utils ----------------\n",
        "KW = {\n",
        "    \"python\": set(\"\"\"\n",
        "False None True and as assert async await break class continue def del elif else\n",
        "except finally for from global if import in is lambda nonlocal not or pass raise\n",
        "return try while with yield print range len int float str list dict set tuple\n",
        "\"\"\".split()),\n",
        "    \"java\": set(\"\"\"abstract assert boolean break byte case catch char class const continue\n",
        "default do double else enum extends final finally float for goto if implements import instanceof int\n",
        "interface long native new package private protected public return short static strictfp super switch synchronized this throw throws transient try void volatile while\n",
        "\"\"\".split()),\n",
        "    \"cpp\": set(\"\"\"alignas alignof and and_eq asm atomic_cancel atomic_commit atomic_noexcept auto bitand bitor bool break case catch char char8_t char16_t char32_t class compl concept\n",
        "const consteval constexpr constinit const_cast continue co_await co_return co_yield decltype default delete do double dynamic_cast else enum explicit export extern false float for friend goto if\n",
        "inline int long mutable namespace new noexcept not not_eq nullptr operator or or_eq private protected public register reinterpret_cast requires return short signed sizeof static static_assert static_cast\n",
        "struct switch synchronized template this thread_local throw true try typedef typeid typename union unsigned using virtual void volatile wchar_t while xor xor_eq\n",
        "\"\"\".split()),\n",
        "    \"c\": set(\"\"\"auto break case char const continue default do double else enum extern float for goto if inline int long register restrict return short signed sizeof static struct switch typedef union unsigned void volatile while\"\"\".split()),\n",
        "    \"csharp\": set(\"\"\"abstract as base bool break byte case catch char checked class const continue decimal default delegate do double else enum event explicit extern false finally fixed float for foreach goto if implicit in int interface internal is lock long namespace new null object operator out override params private protected public readonly ref return sbyte sealed short sizeof stackalloc static string struct switch this throw true try typeof uint ulong unchecked unsafe ushort using virtual void volatile while\"\"\".split()),\n",
        "    \"javascript\": set(\"\"\"break case catch class const continue debugger default delete do else export extends finally for function if import in instanceof let new return super switch this throw try typeof var void while with yield\"\"\".split()),\n",
        "    \"php\": set(\"\"\"abstract and array as break callable case catch class clone const continue declare default die do echo else elseif empty enddeclare endfor endforeach endif endswitch endwhile eval exit extends final finally fn for foreach function global goto if implements include include_once instanceof insteadof interface isset list matches namespace new or print private protected public readonly require require_once return static switch throw trait try unset use var while xor yield\"\"\".split()),\n",
        "    \"go\": set(\"\"\"break case chan const continue default defer else fallthrough for func go goto if import interface map package range return select struct switch type var\"\"\".split()),\n",
        "}\n",
        "def normalize_language(s: str) -> str:\n",
        "    t = str(s).strip().lower()\n",
        "    t = {\"py\":\"python\",\"py3\":\"python\",\"python3\":\"python\",\"c++\":\"cpp\",\"cs\":\"csharp\",\"js\":\"javascript\",\"node\":\"javascript\",\"golang\":\"go\"}.get(t, t)\n",
        "    return t\n",
        "\n",
        "def read_df(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_parquet(path).copy()\n",
        "    assert {\"code\",\"generator\",\"label\",\"language\"}.issubset(df.columns)\n",
        "    df[\"language\"] = df[\"language\"].apply(normalize_language)\n",
        "    if \"domain\" not in df.columns:\n",
        "        df[\"domain\"] = \"algorithmic\"\n",
        "    df[\"code\"] = df[\"code\"].astype(str)\n",
        "    return df\n",
        "\n",
        "def label_to_int(x):\n",
        "    s = str(x).lower()\n",
        "    if s in {\"1\",\"machine\",\"ai\",\"llm\",\"generated\"}: return 1\n",
        "    if s in {\"0\",\"human\"}: return 0\n",
        "    raise ValueError(f\"Unexpected label value: {x}\")\n",
        "\n",
        "# ---------------- Identifier renaming (safe-ish, consistent) ----------------\n",
        "ID_RE = re.compile(r\"\\b[_a-zA-Z][_a-zA-Z0-9]*\\b\")\n",
        "\n",
        "def rename_identifiers(code: str, lang: str, max_ids: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Conservative, per-snippet consistent renamer:\n",
        "    - skips keywords\n",
        "    - skips very short names (len<=2)\n",
        "    - only renames lowercase-starting identifiers (to avoid Types/ClassNames)\n",
        "    \"\"\"\n",
        "    kws = KW.get(lang, set())\n",
        "    mapping: Dict[str,str] = {}\n",
        "    counter = 1\n",
        "\n",
        "    def repl(m):\n",
        "        nonlocal counter\n",
        "        tok = m.group(0)\n",
        "        if tok in kws: return tok\n",
        "        if not tok[0].islower(): return tok\n",
        "        if len(tok) <= 2: return tok\n",
        "        if tok not in mapping:\n",
        "            if counter > max_ids: return tok\n",
        "            mapping[tok] = f\"v{counter}\"\n",
        "            counter += 1\n",
        "        return mapping[tok]\n",
        "\n",
        "    try:\n",
        "        return ID_RE.sub(repl, code)\n",
        "    except Exception:\n",
        "        return code\n",
        "\n",
        "# ---------------- Ensemble variants ----------------\n",
        "_comment_cpp_line = re.compile(r\"//.*?$\", flags=re.MULTILINE)\n",
        "_comment_cpp_block = re.compile(r\"/\\*.*?\\*/\", flags=re.DOTALL)\n",
        "_comment_hash = re.compile(r\"#.*?$\", flags=re.MULTILINE)\n",
        "def strip_comments(text: str, lang: str) -> str:\n",
        "    if lang == \"python\":\n",
        "        return _comment_hash.sub(\"\", text)\n",
        "    return _comment_cpp_block.sub(\"\", _comment_cpp_line.sub(\"\", text))\n",
        "\n",
        "def ws_tidy(text: str, lang: str) -> str:\n",
        "    lines = text.splitlines()\n",
        "    lines = [ln.rstrip() for ln in lines]\n",
        "    out, blank = [], 0\n",
        "    for ln in lines:\n",
        "        if ln.strip()==\"\":\n",
        "            blank += 1\n",
        "            if blank <= 1: out.append(ln)\n",
        "        else:\n",
        "            blank = 0; out.append(ln)\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def make_variants(code: str, lang: str) -> List[str]:\n",
        "    v = [code]\n",
        "    try: v.append(strip_comments(code, lang))\n",
        "    except: v.append(code)\n",
        "    try: v.append(ws_tidy(code, lang))\n",
        "    except: v.append(code)\n",
        "    try: v.append(rename_identifiers(code, lang))\n",
        "    except: v.append(code)\n",
        "    return v\n",
        "\n",
        "# ---------------- Model ----------------\n",
        "class CodeBERTBinaryClassifier(nn.Module):\n",
        "    def __init__(self, model_name: str):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "        self.tok = AutoTokenizer.from_pretrained(model_name)\n",
        "        h = self.encoder.config.hidden_size\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.cls  = nn.Linear(h, 1)\n",
        "\n",
        "    def logits_for_texts(self, texts: List[str]) -> torch.Tensor:\n",
        "        enc = self.tok(texts, max_length=cfg.max_len, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        out = self.encoder(**enc)\n",
        "        cls_vec = out.last_hidden_state[:,0,:]\n",
        "        return self.cls(self.drop(cls_vec)).squeeze(-1)\n",
        "\n",
        "# ---------------- Build data ----------------\n",
        "val_df  = read_df(cfg.val_parquet)\n",
        "test_df = read_df(cfg.test_parquet)\n",
        "y_val   = val_df[\"label\"].apply(label_to_int).values.astype(int)\n",
        "y_test  = test_df[\"label\"].apply(label_to_int).values.astype(int)\n",
        "\n",
        "# ---------------- Load model ----------------\n",
        "model = CodeBERTBinaryClassifier(cfg.model_name).to(device)\n",
        "state = torch.load(cfg.ckpt_path, map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "print(f\"✅ Loaded checkpoint: {cfg.ckpt_path}\")\n",
        "\n",
        "# ---------------- Ensemble scorer ----------------\n",
        "def ensemble_logits(df: pd.DataFrame) -> np.ndarray:\n",
        "    logits_sum = np.zeros(len(df), dtype=np.float32)\n",
        "    counts     = np.zeros(len(df), dtype=np.int32)\n",
        "    batch_texts, idxs = [], []\n",
        "\n",
        "    def flush():\n",
        "        nonlocal batch_texts, idxs, logits_sum, counts\n",
        "        if not batch_texts: return\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\", enabled=(device==\"cuda\")):\n",
        "            lg = model.logits_for_texts(batch_texts).detach().float().cpu().numpy()\n",
        "        for k, i in enumerate(idxs):\n",
        "            logits_sum[i] += lg[k]; counts[i] += 1\n",
        "        batch_texts, idxs = [], []\n",
        "\n",
        "    for i, (code, lang) in enumerate(zip(df[\"code\"], df[\"language\"])):\n",
        "        prefix = f\"<lang:{lang}>\\n\"\n",
        "        for txt in make_variants(code, lang):\n",
        "            batch_texts.append(prefix + txt)\n",
        "            idxs.append(i)\n",
        "            if len(batch_texts) >= cfg.batch_size:\n",
        "                flush()\n",
        "    flush()\n",
        "    return logits_sum / np.maximum(1, counts)\n",
        "\n",
        "# ---------------- Score validation (ensemble) ----------------\n",
        "print(\"Scoring validation with ensemble (4 variants)…\")\n",
        "val_logits = ensemble_logits(val_df); gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# ---------------- Temperature scaling on validation ----------------\n",
        "def fit_temperature(logits: np.ndarray, labels: np.ndarray, max_iter=100) -> float:\n",
        "    x = torch.tensor(logits, dtype=torch.float32, device=device)\n",
        "    y = torch.tensor(labels, dtype=torch.float32, device=device)\n",
        "    T = torch.tensor(1.0, dtype=torch.float32, device=device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([T], lr=0.1, max_iter=max_iter, line_search_fn=\"strong_wolfe\")\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "    def closure():\n",
        "        opt.zero_grad()\n",
        "        loss = bce(x / T, y)\n",
        "        loss.backward(); return loss\n",
        "    opt.step(closure)\n",
        "    t = float(T.detach().clamp_min(1e-3).cpu())\n",
        "    return t\n",
        "\n",
        "T = fit_temperature(val_logits, y_val)\n",
        "val_probs = 1 / (1 + np.exp(-val_logits / T))\n",
        "print(f\"🔧 Temperature T = {T:.4f}\")\n",
        "\n",
        "# ---------------- Global & per-language thresholds (from VAL) ----------------\n",
        "def best_threshold(y_true, y_prob):\n",
        "    best_t, best_f1 = 0.5, -1.0\n",
        "    for t in np.linspace(0,1,401):\n",
        "        f1 = f1_score(y_true, (y_prob>=t).astype(int), average=\"macro\")\n",
        "        if f1 > best_f1: best_t, best_f1 = float(t), float(f1)\n",
        "    return best_t, best_f1\n",
        "\n",
        "t_global, f1g = best_threshold(y_val, val_probs)\n",
        "print(f\"🎯 Global best threshold: {t_global:.3f} (Val Macro-F1={f1g:.4f})\")\n",
        "\n",
        "per_lang_t: Dict[str,float] = {}\n",
        "for L in sorted(np.unique(val_df[\"language\"].values)):\n",
        "    m = (val_df[\"language\"].values==L)\n",
        "    if m.sum() < 10:  # too few to tune\n",
        "        per_lang_t[L] = t_global\n",
        "        continue\n",
        "    tL, f1L = best_threshold(y_val[m], val_probs[m])\n",
        "    per_lang_t[L] = tL\n",
        "    print(f\"  - {L:>10}: t*={tL:.3f}  (n={m.sum():4d})\")\n",
        "\n",
        "# ---------------- Score TEST (ensemble + calibration) ----------------\n",
        "print(\"Scoring test with ensemble (4 variants)…\")\n",
        "test_logits = ensemble_logits(test_df); gc.collect(); torch.cuda.empty_cache()\n",
        "test_probs  = 1 / (1 + np.exp(-test_logits / T))\n",
        "\n",
        "# Evaluate both orientations and keep the better one (since test is labeled)\n",
        "def evaluate_with_orientation(y_true, probs, orientation: str):\n",
        "    p = probs if orientation==\"normal\" else (1 - probs)\n",
        "    # per-language thresholding\n",
        "    langs = test_df[\"language\"].values\n",
        "    preds = np.zeros_like(y_true)\n",
        "    for L in np.unique(langs):\n",
        "        tL = per_lang_t.get(L, t_global)\n",
        "        mask = (langs==L)\n",
        "        preds[mask] = (p[mask] >= tL).astype(int)\n",
        "    # metrics\n",
        "    try: auroc = roc_auc_score(y_true, p)\n",
        "    except: auroc = float(\"nan\")\n",
        "    res = dict(\n",
        "        orientation=orientation,\n",
        "        AUROC=auroc,\n",
        "        AUPRC=average_precision_score(y_true, p),\n",
        "        Acc=accuracy_score(y_true, preds),\n",
        "        MacroF1=f1_score(y_true, preds, average=\"macro\"),\n",
        "        Prec=precision_score(y_true, preds, average=\"macro\", zero_division=0),\n",
        "        Rec=recall_score(y_true, preds, average=\"macro\", zero_division=0),\n",
        "        preds=preds, probs=p\n",
        "    )\n",
        "    return res\n",
        "\n",
        "y_test = test_df[\"label\"].apply(label_to_int).values.astype(int)\n",
        "res_norm = evaluate_with_orientation(y_test, test_probs, \"normal\")\n",
        "res_flip = evaluate_with_orientation(y_test, test_probs, \"flipped\")\n",
        "\n",
        "best = res_flip if (res_flip[\"MacroF1\"] > res_norm[\"MacroF1\"]) else res_norm\n",
        "print(\"\\n=== TEST (choose best orientation automatically) ===\")\n",
        "for name, val in best.items():\n",
        "    if name in {\"preds\",\"probs\",\"orientation\"}: continue\n",
        "    print(f\"{name}: {val:.4f}\")\n",
        "print(\"Chosen orientation:\", best[\"orientation\"])\n",
        "\n",
        "# ---------------- Confusion matrix ----------------\n",
        "cm = confusion_matrix(y_test, best[\"preds\"])\n",
        "cmn = cm / cm.sum(axis=1, keepdims=True)\n",
        "print(\"\\nConfusion matrix (raw):\\n\", cm)\n",
        "print(\"\\nConfusion matrix (normalized):\\n\", np.round(cmn,3))\n",
        "\n",
        "# ---------------- Save CSV with predictions ----------------\n",
        "out = test_df[[\"code\",\"generator\",\"label\",\"language\"]].copy()\n",
        "# store calibrated prob in the chosen orientation\n",
        "out[\"prob_machine_calibrated\"] = best[\"probs\"]\n",
        "# preserve label type style\n",
        "if np.issubdtype(test_df[\"label\"].dtype, np.number):\n",
        "    out[\"pred_label\"] = best[\"preds\"]\n",
        "else:\n",
        "    out[\"pred_label\"] = np.where(best[\"preds\"]==1, \"machine\", \"human\")\n",
        "save_csv = os.path.join(cfg.out_dir, \"taskA_test_with_predictions_calib_ensem_thres_oriented.csv\")\n",
        "out.to_csv(save_csv, index=False)\n",
        "print(f\"\\nSaved predictions to: {save_csv}\")\n",
        "\n",
        "# ---------------- Per-language report ----------------\n",
        "langs = test_df[\"language\"].values\n",
        "print(\"\\n=== Per-language (TEST) using chosen orientation ===\")\n",
        "for L in sorted(np.unique(langs)):\n",
        "    m = (langs==L)\n",
        "    if m.sum()==0: continue\n",
        "    y, p, yhat = y_test[m], best[\"probs\"][m], best[\"preds\"][m]\n",
        "    try: au = roc_auc_score(y, p)\n",
        "    except: au = float(\"nan\")\n",
        "    print(f\"{L:>10}  n={m.sum():4d}  Acc={accuracy_score(y,yhat):.3f}  F1={f1_score(y,yhat,average='macro'):.3f}  AUROC={au:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEGQuLqQYDeP",
        "outputId": "c4d0fcd1-0f10-4783-a429-4b4ef1f246b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded checkpoint: /content/drive/MyDrive/semeval_taskA_outputs/taskA_codebert_best.pt\n",
            "Scoring validation with ensemble (4 variants)…\n",
            "🔧 Temperature T = 1.2169\n",
            "🎯 Global best threshold: 0.370 (Val Macro-F1=0.9954)\n",
            "  -        cpp: t*=0.318  (n=4679)\n",
            "  -       java: t*=0.135  (n=3860)\n",
            "  -     python: t*=0.380  (n=91461)\n",
            "Scoring test with ensemble (4 variants)…\n",
            "\n",
            "=== TEST (choose best orientation automatically) ===\n",
            "AUROC: 0.6086\n",
            "AUPRC: 0.2803\n",
            "Acc: 0.7380\n",
            "MacroF1: 0.5484\n",
            "Prec: 0.5722\n",
            "Rec: 0.5468\n",
            "Chosen orientation: flipped\n",
            "\n",
            "Confusion matrix (raw):\n",
            " [[693  84]\n",
            " [178  45]]\n",
            "\n",
            "Confusion matrix (normalized):\n",
            " [[0.892 0.108]\n",
            " [0.798 0.202]]\n",
            "\n",
            "Saved predictions to: /content/drive/MyDrive/semeval_taskA_outputs/taskA_test_with_predictions_calib_ensem_thres_oriented.csv\n",
            "\n",
            "=== Per-language (TEST) using chosen orientation ===\n",
            "         c  n=  51  Acc=0.765  F1=0.627  AUROC=0.641\n",
            "        c#  n= 122  Acc=0.811  F1=0.597  AUROC=0.824\n",
            "       cpp  n=  75  Acc=0.773  F1=0.616  AUROC=0.572\n",
            "        go  n=  60  Acc=0.767  F1=0.580  AUROC=0.594\n",
            "      java  n= 256  Acc=0.836  F1=0.579  AUROC=0.800\n",
            "javascript  n=  85  Acc=0.776  F1=0.721  AUROC=0.704\n",
            "       php  n=  48  Acc=0.917  F1=0.478  AUROC=0.496\n",
            "    python  n= 303  Acc=0.568  F1=0.406  AUROC=0.384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITfBQSp_Zz7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYdyvLjZQbpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task - 1 Attempt - 2"
      ],
      "metadata": {
        "id": "d--ubQ4jQdne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# update these to your actual file paths:\n",
        "train_path = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_training_set_1.parquet\"\n",
        "val_path   = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet\"\n",
        "test_path  = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"\n",
        "\n",
        "def describe_split(name, path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"❌ {name} not found at {path}\")\n",
        "        return None\n",
        "    df = pd.read_parquet(path)\n",
        "    print(f\"\\n=== {name.upper()} ({len(df):,} rows) ===\")\n",
        "    print(\"Columns:\", list(df.columns))\n",
        "    print(\"Null counts:\\n\", df.isnull().sum())\n",
        "    print(\"\\nSample rows:\")\n",
        "    print(df.head(2))\n",
        "    print(\"\\nLabel distribution:\")\n",
        "    print(df[\"label\"].value_counts(dropna=False, normalize=True).round(3).to_dict() if \"label\" in df else \"no label col\")\n",
        "    if \"language\" in df:\n",
        "        print(\"\\nLanguages (top 10):\")\n",
        "        print(df[\"language\"].value_counts().head(10))\n",
        "    if \"generator\" in df:\n",
        "        print(\"\\nGenerators (top 10):\")\n",
        "        print(df[\"generator\"].value_counts().head(10))\n",
        "    # code stats\n",
        "    code_lens = df[\"code\"].astype(str).apply(len)\n",
        "    print(f\"\\nCode length: mean={code_lens.mean():.1f},  median={code_lens.median():.1f},  max={code_lens.max():,}\")\n",
        "    long = (code_lens > 10000).sum()\n",
        "    if long:\n",
        "        print(f\"⚠️ {long} samples >10k chars\")\n",
        "    return df\n",
        "\n",
        "train_df = describe_split(\"train\", train_path)\n",
        "val_df   = describe_split(\"validation\", val_path)\n",
        "test_df  = describe_split(\"test\", test_path)\n",
        "\n",
        "# class balance check\n",
        "if train_df is not None and \"label\" in train_df:\n",
        "    ratio = train_df[\"label\"].value_counts(normalize=True)\n",
        "    print(\"\\nOverall train human/machine ratio:\")\n",
        "    print(ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHu5rtkPQgR9",
        "outputId": "9de0f760-33e3-4c40-bdc2-e4dc14a962f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN (500,000 rows) ===\n",
            "Columns: ['code', 'generator', 'label', 'language']\n",
            "Null counts:\n",
            " code         0\n",
            "generator    0\n",
            "label        0\n",
            "language     0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows:\n",
            "                                                code                generator  \\\n",
            "0  (a, b, c, d) = [int(x) for x in input().split(...                    human   \n",
            "1  valid version for the language; all others can...  Qwen/Qwen2.5-Coder-1.5B   \n",
            "\n",
            "   label language  \n",
            "0      0   Python  \n",
            "1      1   Python  \n",
            "\n",
            "Label distribution:\n",
            "{1: 0.523, 0: 0.477}\n",
            "\n",
            "Languages (top 10):\n",
            "language\n",
            "Python    457306\n",
            "C++        23392\n",
            "Java       19302\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Generators (top 10):\n",
            "generator\n",
            "human                                  238475\n",
            "microsoft/Phi-3-medium-4k-instruct      16545\n",
            "microsoft/Phi-3.5-mini-instruct          9869\n",
            "01-ai/Yi-Coder-9B                        9815\n",
            "bigcode/starcoder                        9780\n",
            "microsoft/phi-2                          9494\n",
            "Qwen/Qwen2.5-Coder-1.5B-Instruct         9017\n",
            "bigcode/starcoder2-15b                   8824\n",
            "meta-llama/Llama-3.3-70B-Instruct        8760\n",
            "codellama/CodeLlama-70b-Instruct-hf      8715\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Code length: mean=836.9,  median=464.0,  max=475,006\n",
            "⚠️ 850 samples >10k chars\n",
            "\n",
            "=== VALIDATION (100,000 rows) ===\n",
            "Columns: ['code', 'generator', 'label', 'language']\n",
            "Null counts:\n",
            " code         0\n",
            "generator    0\n",
            "label        0\n",
            "language     0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows:\n",
            "                                                code                generator  \\\n",
            "0  import sys\\ninf = float('inf')\\nfrom bisect im...                    human   \n",
            "1  def Range(a): return min(max(a, -10), 10)\\n\\nd...  meta-llama/Llama-3.1-8B   \n",
            "\n",
            "   label language  \n",
            "0      0   Python  \n",
            "1      1   Python  \n",
            "\n",
            "Label distribution:\n",
            "{1: 0.523, 0: 0.477}\n",
            "\n",
            "Languages (top 10):\n",
            "language\n",
            "Python    91461\n",
            "C++        4679\n",
            "Java       3860\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Generators (top 10):\n",
            "generator\n",
            "human                                 47695\n",
            "microsoft/Phi-3-medium-4k-instruct     3165\n",
            "microsoft/Phi-3.5-mini-instruct        2047\n",
            "microsoft/phi-2                        1966\n",
            "01-ai/Yi-Coder-9B                      1950\n",
            "Qwen/Qwen2.5-Coder-1.5B-Instruct       1903\n",
            "bigcode/starcoder2-15b                 1872\n",
            "bigcode/starcoder                      1857\n",
            "microsoft/Phi-3-small-8k-instruct      1814\n",
            "bigcode/starcoder2-3b                  1760\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Code length: mean=835.5,  median=461.0,  max=79,243\n",
            "⚠️ 178 samples >10k chars\n",
            "\n",
            "=== TEST (1,000 rows) ===\n",
            "Columns: ['code', 'generator', 'label', 'language']\n",
            "Null counts:\n",
            " code         0\n",
            "generator    0\n",
            "label        0\n",
            "language     0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows:\n",
            "                                                code generator  label language\n",
            "0  public Vector To(Vector o)\\n        {\\n       ...     Human      0       C#\n",
            "1  func (v *DefaultMessageSyntaxValidator) Valida...     Human      0       Go\n",
            "\n",
            "Label distribution:\n",
            "{0: 0.777, 1: 0.223}\n",
            "\n",
            "Languages (top 10):\n",
            "language\n",
            "Python        303\n",
            "Java          256\n",
            "C#            122\n",
            "JavaScript     85\n",
            "C++            75\n",
            "Go             60\n",
            "C              51\n",
            "PHP            48\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Generators (top 10):\n",
            "generator\n",
            "Human                                        713\n",
            "human                                         64\n",
            "GPT-4o                                        21\n",
            "deepseek-ai/DeepSeek-V3-0324                  10\n",
            "01-ai/Yi-Coder-9B-Chat                         8\n",
            "meta-llama/Llama-4-Scout-17B-16E-Instruct      7\n",
            "Qwen/Qwen2.5-Coder-1.5B-Instruct               7\n",
            "mistralai/Mistral-Small-24B-Instruct-2501      7\n",
            "meta-llama/Llama-3.1-8B-Instruct               7\n",
            "gemini-2.0-flash-lite                          7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Code length: mean=1370.2,  median=848.0,  max=12,472\n",
            "⚠️ 4 samples >10k chars\n",
            "\n",
            "Overall train human/machine ratio:\n",
            "label\n",
            "1    0.52305\n",
            "0    0.47695\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0 – Environment Setup (run first)"
      ],
      "metadata": {
        "id": "2TU3a6AMTXpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 0 — Setup: installs, imports, config (A100, full data)\n",
        "# =====================================================================\n",
        "!pip -q install \"transformers==4.43.4\" \"peft==0.12.0\" \"pyarrow\" \"pandas\" \"tqdm\" \"scikit-learn\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "import os, random, json, math, time, re\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    f1_score, accuracy_score, confusion_matrix\n",
        ")\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# reproducibility\n",
        "SEED = 1337\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED); random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# A100 quality-of-life: allow TF32 (fast + stable)\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"✅ Device:\", device)\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    # paths\n",
        "    train_path: str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_training_set_1.parquet\"\n",
        "    val_path:   str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet\"  # ~100k\n",
        "    test_path:  str = \"/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet\"\n",
        "\n",
        "    # output\n",
        "    out_dir:   str = \"/content/drive/MyDrive/semeval_taskA_outputs_starcoder2_A100_full\"\n",
        "    ckpt_name: str = \"taskA_starcoder2_A100_best.pt\"\n",
        "\n",
        "    # model\n",
        "    model_name: str = \"bigcode/starcoder2-3b\"\n",
        "    max_len:    int = 2048    # A100 can handle full 2k context comfortably\n",
        "\n",
        "    # training (full-data defaults for A100)\n",
        "    epochs:        int   = 1          # start with 2; you can raise to 3+ later\n",
        "    batch_size:    int   = 1         # micro-batch per step\n",
        "    grad_accum:    int   = 16         # effective batch = 4*16 = 64 sequences\n",
        "    eval_bs:       int   = 1         # eval has no grad; raise to 24–32 if VRAM allows\n",
        "    lr:            float = 5e-6\n",
        "    warmup_ratio:  float = 0.06\n",
        "    weight_decay:  float = 0.01\n",
        "    max_grad_norm: float = 1.0\n",
        "\n",
        "    # LoRA\n",
        "    lora_r:        int   = 16\n",
        "    lora_alpha:    int   = 32\n",
        "    lora_dropout:  float = 0.05\n",
        "\n",
        "    # features\n",
        "    use_stylo:     bool  = True       # 24-D stylometrics\n",
        "    lang_reweight: bool  = True       # inverse-freq per language\n",
        "\n",
        "    # precision\n",
        "    use_bf16:      bool  = True       # A100 supports bf16 → stable & fast\n",
        "\n",
        "    # validation / training caps (FULL RUN => None)\n",
        "    TRAIN_MAX_BATCHES: Optional[int] = None   # None = use ALL ~500k\n",
        "    VAL_MAX_BATCHES:   Optional[int] = None   # None = use ALL ~100k\n",
        "    FAST_VAL:          bool = False           # False = full validation passes\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "print(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COWE9upgTaTI",
        "outputId": "6c376f0e-b0fd-4cd9-be85-8a8f89223d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "✅ Device: cuda\n",
            "CFG(train_path='/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_training_set_1.parquet', val_path='/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_validation_set.parquet', test_path='/content/drive/MyDrive/SemEval-2026-Task13/task_a/task_a_test_set_sample.parquet', out_dir='/content/drive/MyDrive/semeval_taskA_outputs_starcoder2_A100_full', ckpt_name='taskA_starcoder2_A100_best.pt', model_name='bigcode/starcoder2-3b', max_len=2048, epochs=1, batch_size=1, grad_accum=16, eval_bs=1, lr=5e-06, warmup_ratio=0.06, weight_decay=0.01, max_grad_norm=1.0, lora_r=16, lora_alpha=32, lora_dropout=0.05, use_stylo=True, lang_reweight=True, use_bf16=True, TRAIN_MAX_BATCHES=None, VAL_MAX_BATCHES=None, FAST_VAL=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 – Configuration (L4 profile)"
      ],
      "metadata": {
        "id": "Bsg-6mLfTOrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 1 — Load parquet → DataFrames, normalize, clean code (A100/full)\n",
        "# =====================================================================\n",
        "def normalize_language(s: str) -> str:\n",
        "    t = str(s if s is not None else \"\").strip().lower()\n",
        "    return {\n",
        "        \"py\":\"python\",\"py3\":\"python\",\"python3\":\"python\",\n",
        "        \"c++\":\"cpp\",\"cs\":\"csharp\",\"c#\":\"csharp\",\n",
        "        \"js\":\"javascript\",\"node\":\"javascript\",\n",
        "        \"golang\":\"go\"\n",
        "    }.get(t, t)\n",
        "\n",
        "LANG_NAMES = {\"python\",\"java\",\"cpp\",\"c\",\"csharp\",\"javascript\",\"php\",\"go\"}\n",
        "MAX_LINE_CHARS = 2000\n",
        "\n",
        "def _is_bare_language_header(line: str) -> bool:\n",
        "    s = str(line).strip().strip(\"`\").lower()\n",
        "    return s in LANG_NAMES\n",
        "\n",
        "def clean_code(raw: str) -> str:\n",
        "    if raw is None:\n",
        "        return \"\"\n",
        "    lines = str(raw).splitlines()\n",
        "    # drop leading bare language header if present\n",
        "    if lines:\n",
        "        i = next((k for k, ln in enumerate(lines) if ln.strip() != \"\"), None)\n",
        "        if i is not None and _is_bare_language_header(lines[i]):\n",
        "            lines.pop(i)\n",
        "    # clamp ultra-long lines (keeps structure, avoids crazy memory)\n",
        "    clipped = []\n",
        "    for ln in lines:\n",
        "        ln = ln.rstrip()\n",
        "        if len(ln) > MAX_LINE_CHARS:\n",
        "            ln = ln[:MAX_LINE_CHARS]\n",
        "        clipped.append(ln)\n",
        "    return \"\\n\".join(clipped)\n",
        "\n",
        "def load_df(path: str) -> pd.DataFrame:\n",
        "    # Read only what we need → lower RAM & faster IO\n",
        "    df = pd.read_parquet(path, columns=[\"code\",\"generator\",\"label\",\"language\"]).copy()\n",
        "\n",
        "    # basic hygiene\n",
        "    df[\"code\"] = df[\"code\"].fillna(\"\").astype(str).str.strip()\n",
        "    df[\"language\"] = df[\"language\"].fillna(\"\").apply(normalize_language)\n",
        "\n",
        "    # optional domain (keep stable API)\n",
        "    if \"domain\" not in df.columns:\n",
        "        df[\"domain\"] = \"algorithmic\"\n",
        "\n",
        "    # clean code text\n",
        "    df[\"code_clean\"] = df[\"code\"].apply(clean_code)\n",
        "\n",
        "    # ensure strictly binary label → int8 (saves RAM)\n",
        "    if np.issubdtype(df[\"label\"].dtype, np.number):\n",
        "        df[\"label_bin\"] = df[\"label\"].astype(int).clip(0, 1).astype(np.int8)\n",
        "    else:\n",
        "        def to_bin(x):\n",
        "            s = str(x).strip().lower()\n",
        "            if s in {\"0\",\"human\"}: return 0\n",
        "            if s in {\"1\",\"machine\",\"ai\",\"generated\",\"llm\"}: return 1\n",
        "            raise ValueError(f\"unexpected label: {x}\")\n",
        "        df[\"label_bin\"] = df[\"label\"].map(to_bin).astype(np.int8)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = load_df(cfg.train_path)\n",
        "val_df   = load_df(cfg.val_path)\n",
        "test_df  = load_df(cfg.test_path)\n",
        "\n",
        "print(f\"TRAIN: {len(train_df):,}  VAL: {len(val_df):,}  TEST: {len(test_df):,}\")\n",
        "print(\"Train label ratio:\", train_df[\"label_bin\"].value_counts(normalize=True).to_dict())\n",
        "print(\"Val   label ratio:\",   val_df[\"label_bin\"].value_counts(normalize=True).to_dict())\n",
        "print(\"Test  label ratio:\",  test_df[\"label_bin\"].value_counts(normalize=True).to_dict())\n",
        "\n",
        "# (Optional) quick per-language counts to spot imbalance\n",
        "print(\"\\nPer-language (train) top 10:\")\n",
        "print(train_df[\"language\"].value_counts().head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUIEyvsPQysN",
        "outputId": "81627520-c2d3-4c7c-c4df-e573620c52ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: 500,000  VAL: 100,000  TEST: 1,000\n",
            "Train label ratio: {1: 0.52305, 0: 0.47695}\n",
            "Val   label ratio: {1: 0.52305, 0: 0.47695}\n",
            "Test  label ratio: {0: 0.777, 1: 0.223}\n",
            "\n",
            "Per-language (train) top 10:\n",
            "language\n",
            "python    457306\n",
            "cpp        23392\n",
            "java       19302\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 2 (data prep)"
      ],
      "metadata": {
        "id": "P5kYJCUzU-Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 2 — Tokenizer (make sure PAD exists and max length is aligned)\n",
        "# =====================================================================\n",
        "tok = AutoTokenizer.from_pretrained(cfg.model_name, use_fast=True)\n",
        "tok.padding_side = \"right\"\n",
        "tok.truncation_side = \"right\"\n",
        "\n",
        "# StarCoder2 has no dedicated PAD — use EOS as PAD (safe for classification)\n",
        "if tok.pad_token is None:\n",
        "    # guard if eos also missing (very rare)\n",
        "    if tok.eos_token is None:\n",
        "        tok.add_special_tokens({\"eos_token\": \"</s>\"})\n",
        "    tok.pad_token = tok.eos_token\n",
        "    tok.pad_token_id = tok.eos_token_id\n",
        "\n",
        "# keep tokenizer and our config in sync to avoid warnings\n",
        "tok.model_max_length = cfg.max_len\n",
        "\n",
        "print(\"Tokenizer:\", tok.__class__.__name__,\n",
        "      \"| vocab:\", tok.vocab_size,\n",
        "      \"| pad_token_id:\", tok.pad_token_id,\n",
        "      \"| model_max_length:\", tok.model_max_length)\n",
        "\n",
        "# =====================================================================\n",
        "# STEP 2b — Stylometrics (24-D) for optional fusion\n",
        "# =====================================================================\n",
        "KW = {\n",
        "  \"python\": set(\"False None True and as assert async await break class continue def del elif else except finally for from global if import in is lambda nonlocal not or pass raise return try while with yield\".split()),\n",
        "  \"java\": set(\"abstract assert boolean break byte case catch char class const continue default do double else enum extends final finally float for goto if implements import instanceof int interface long native new package private protected public return short static strictfp super switch synchronized this throw throws transient try void volatile while\".split()),\n",
        "  \"cpp\": set(\"alignas alignof and and_eq asm atomic_cancel atomic_commit atomic_noexcept auto bitand bitor bool break case catch char char8_t char16_t char32_t class compl concept const consteval constexpr constinit const_cast continue co_await co_return co_yield decltype default delete do double dynamic_cast else enum explicit export extern false float for friend goto if inline int long mutable namespace new noexcept not not_eq nullptr operator or or_eq private protected public register reinterpret_cast requires return short signed sizeof static static_assert static_cast struct switch synchronized template this thread_local throw true try typedef typeid typename union unsigned using virtual void volatile wchar_t while xor xor_eq\".split()),\n",
        "  \"c\": set(\"auto break case char const continue default do double else enum extern float for goto if inline int long register restrict return short signed sizeof static struct switch typedef union unsigned void volatile while\".split()),\n",
        "  \"csharp\": set(\"abstract as base bool break byte case catch char checked class const continue decimal default delegate do double else enum event explicit extern false finally fixed float for foreach goto if implicit in int interface internal is lock long namespace new null object operator out override params private protected public readonly ref return sbyte sealed short sizeof stackalloc static string struct switch this throw true try typeof uint ulong unchecked unsafe ushort using virtual void volatile while\".split()),\n",
        "  \"javascript\": set(\"break case catch class const continue debugger default delete do else export extends finally for function if import in instanceof let new return super switch this throw try typeof var void while with yield\".split()),\n",
        "  \"php\": set(\"abstract and array as break callable case catch class clone const continue declare default die do echo else elseif empty enddeclare endfor endforeach endif endswitch endwhile eval exit extends final finally fn for foreach function global goto if implements include include_once instanceof insteadof interface isset list matches namespace new or print private protected public readonly require require_once return static switch throw trait try unset use var while xor yield\".split()),\n",
        "  \"go\": set(\"break case chan const continue default defer else fallthrough for func go goto if import interface map package range return select struct switch type var\".split()),\n",
        "}\n",
        "\n",
        "ID_RE = re.compile(r\"\\b[_a-zA-Z][_a-zA-Z0-9]*\\b\")\n",
        "COMMENT_HASH = re.compile(r\"#.*?$\", flags=re.MULTILINE)\n",
        "COMMENT_CPP_LINE  = re.compile(r\"//.*?$\", flags=re.MULTILINE)\n",
        "COMMENT_CPP_BLOCK = re.compile(r\"/\\*.*?\\*/\", flags=re.DOTALL)\n",
        "\n",
        "def strip_comments(code: str, lang: str) -> str:\n",
        "    if lang == \"python\":\n",
        "        return COMMENT_HASH.sub(\"\", code)\n",
        "    txt = COMMENT_CPP_LINE.sub(\"\", code)\n",
        "    return COMMENT_CPP_BLOCK.sub(\"\", txt)\n",
        "\n",
        "def basic_stylo(code: str, lang: str) -> np.ndarray:\n",
        "    # lengths/blank lines\n",
        "    lines = code.splitlines() or [\"\"]\n",
        "    n = len(lines)\n",
        "    lens = [len(x) for x in lines]\n",
        "    num_blank = sum(1 for x in lines if x.strip() == \"\")\n",
        "\n",
        "    # comments ratio\n",
        "    code_nocom = strip_comments(code, lang)\n",
        "    comment_len = max(0, len(code) - len(code_nocom))\n",
        "    comment_ratio = comment_len / max(1, len(code))\n",
        "\n",
        "    # identifiers & kw balance\n",
        "    toks = ID_RE.findall(code)\n",
        "    kws = KW.get(lang, set())\n",
        "    idents = [t for t in toks if t not in kws]\n",
        "    if idents:\n",
        "        from collections import Counter\n",
        "        counts = Counter(idents)\n",
        "        p = np.array(list(counts.values()), dtype=np.float32); p = p / p.sum()\n",
        "        ident_entropy = float(-(p * np.log2(p + 1e-9)).sum())\n",
        "        avg_ident_len = sum(len(t) for t in idents) / len(idents)\n",
        "        upper_ident_ratio = sum(t[0].isupper() for t in idents) / len(idents)\n",
        "        snake_ratio = sum(\"_\" in t for t in idents) / len(idents)\n",
        "        camel_ratio = sum(re.search(r\"[a-z][A-Z]\", t) is not None for t in idents) / len(idents)\n",
        "        digit_ident_ratio = sum(any(ch.isdigit() for ch in t) for t in idents) / len(idents)\n",
        "    else:\n",
        "        ident_entropy = avg_ident_len = upper_ident_ratio = snake_ratio = camel_ratio = digit_ident_ratio = 0.0\n",
        "\n",
        "    # structure/indentation\n",
        "    brace_balance = code.count(\"{\") + code.count(\"(\") + code.count(\"[\") - (code.count(\"}\") + code.count(\")\") + code.count(\"]\"))\n",
        "    indents = [len(ln) - len(ln.lstrip(\" \")) for ln in lines]\n",
        "    max_indent = float(max(indents)) if indents else 0.0\n",
        "    avg_indent = float(sum(indents) / len(indents)) if indents else 0.0\n",
        "\n",
        "    # repetition & entropy\n",
        "    uniq_lines = len(set(lines))\n",
        "    repeated_line_ratio = 1 - (uniq_lines / max(1, n))\n",
        "\n",
        "    chars = list(code)\n",
        "    if chars:\n",
        "        from collections import Counter as C2\n",
        "        c = C2(chars)\n",
        "        p = np.array(list(c.values()), dtype=np.float32); p = p / p.sum()\n",
        "        char_entropy = float(-(p * np.log2(p + 1e-9)).sum())\n",
        "        alnum = sum(ch.isalnum() for ch in chars) / len(chars)\n",
        "        symbol = sum(not ch.isalnum() and not ch.isspace() for ch in chars) / len(chars)\n",
        "        runs = re.findall(r\" +\", code)\n",
        "        avg_run_spaces = float(np.mean([len(r) for r in runs])) if runs else 0.0\n",
        "    else:\n",
        "        char_entropy = alnum = symbol = avg_run_spaces = 0.0\n",
        "\n",
        "    # token stats\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", code, flags=re.UNICODE)\n",
        "    uniq_tokens = len(set(tokens))\n",
        "    token_uniq_ratio = uniq_tokens / max(1, len(tokens))\n",
        "    token_lens = [len(t) for t in tokens] or [0]\n",
        "    avg_token_len = float(np.mean(token_lens))\n",
        "    trigrams = list(zip(tokens, tokens[1:], tokens[2:])) if len(tokens) >= 3 else []\n",
        "    trigram_repeat_ratio = 1 - (len(set(trigrams)) / max(1, len(trigrams)))\n",
        "\n",
        "    feat = np.array([\n",
        "        n, float(np.mean(lens)), float(np.std(lens)), float(max(lens) if lens else 0.0),\n",
        "        comment_ratio, num_blank / max(1, n),\n",
        "        avg_ident_len, ident_entropy,\n",
        "        sum(t in kws for t in toks) / max(1, len(toks)),\n",
        "        upper_ident_ratio, snake_ratio, camel_ratio, digit_ident_ratio,\n",
        "        float(brace_balance), max_indent, avg_indent,\n",
        "        repeated_line_ratio, char_entropy, token_uniq_ratio, alnum, symbol,\n",
        "        avg_token_len, trigram_repeat_ratio, avg_run_spaces\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    return np.nan_to_num(feat, nan=0.0, posinf=1e3, neginf=-1e3).astype(np.float32)\n",
        "\n",
        "print(\"✅ Stylometrics ready (24-D).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "89e19974c2784a308a9dacfc2cf76399",
            "b6c2eeb38ace4354ab95c937b7dcaa36",
            "2f09d69792844bb98f411cd4f6e3f5dc",
            "fc5145b5c36c4499b89da1d46f202fe8",
            "e2092995020e45a99716de7dbc9b8a7d",
            "87881aab0d6247e6a2bcb196642a5674",
            "5be005ae3d9f4fa9b1c1891363acc16a",
            "2c81649c31c64dc3a5dc51d212c0820e",
            "8c145d4890ca4388bb3bd2d73889e9c6",
            "5b2ad4b4ef334f8dad35f91cbc2dbfe2",
            "4c3f055181c040569796ad0dc8a9ac6d",
            "3d80a3634bb2440db4f5dc9a9355bf1a",
            "c3c1da2a42f441fd961eab8e5dae3fc8",
            "b6c192912800443f9cc946bd11197876",
            "caf698e9284040d2b1583b8a31d9fafe",
            "1f1ac3e02da043a1917d6d07acb7e562",
            "d9e7a27a668142c88690c8ec2bf714f9",
            "ec52c3507b3f479fad1c8f23cfc282b1",
            "9674020e3de94b919d17bfbf605f8750",
            "872394336e40425f8d5596b85d324f04",
            "118ceaf4a3a94d3c96884f6e938a064c",
            "e850a2585edb4a278973a4bb7f73793f",
            "2f36b80e06e4497eaf22ca4b77e440d2",
            "b7d23ee9d8e14c7fb72d866960b96c11",
            "3efbe18de1794677be4baedaa195b496",
            "5f07765be3c54cebbc76a291a450a343",
            "edeb721609684d67ae8146c7d706e130",
            "c659d45d0cb44edbb69db00956163202",
            "6f5098bb846945219306445a6f468c5e",
            "21d5e43b7a31497e99597cb8e4a61393",
            "a1e00e586c4d41d7b88be7fcc266eee2",
            "cc5ecb2d6a6d4dc6bf53614f2d17bcf4",
            "2df8089836524441a1a691e96d39ffcf",
            "4b9bb410ba244797889b58c4d219411c",
            "0df6bc8d210c41fd858f8f220831f0b9",
            "9ca3141a6b674785b20ea77fae00180a",
            "51e7c3bfdc1a4db3884bf1d43c7a1efd",
            "195836db110f4c47b13630df0e9d8ee5",
            "13fa13bbff8e4bad8ecfed6d9fd7e25a",
            "102a6cdaf72147b09c6e00d919ad70d8",
            "1dc18909cdd44c8d8968a5712d3b340c",
            "a3c7611f762442f6a44ad9dadd559d2d",
            "034e878984374ee6a9069bdc1fb39116",
            "55d04ecea9884bf0aeb071685507bb52",
            "8ab446b179784ec4a8942b49b18c1069",
            "b4d7a7d8eb83473b80aca51c7761ad74",
            "3f7018c86bbd4127abbe40c13fab9e18",
            "63a49a362d3949d79fa54156da853323",
            "10b1d88d296d491e8eb90c828b76c830",
            "b27cd4158e6a44e788d9febc2136f47b",
            "5f4251f4713b497391d640772e8d9c4b",
            "8e07601ef71346ff9f8a61eb8c6371ef",
            "6d8e5cd9d06d4863afdc3125f8367ea4",
            "7651fc6995b0459fb7b310a7a6830540",
            "15ff8fc79cd14060b8f836f8ae69ea56"
          ]
        },
        "id": "MCB4HIFZUqpa",
        "outputId": "03c4bf19-1149-413c-86fa-f280cdc24e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e19974c2784a308a9dacfc2cf76399"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d80a3634bb2440db4f5dc9a9355bf1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f36b80e06e4497eaf22ca4b77e440d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b9bb410ba244797889b58c4d219411c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/958 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ab446b179784ec4a8942b49b18c1069"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer: GPT2TokenizerFast | vocab: 49152 | pad_token_id: 0 | model_max_length: 2048\n",
            "✅ Stylometrics ready (24-D).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 (tokenizer + dataloaders for StarCoder2 at 2048 tokens)"
      ],
      "metadata": {
        "id": "fBN-LPCdVjHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 3 — Dataset & Dataloaders\n",
        "# =====================================================================\n",
        "class StarCoderDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_len: int, use_stylo: bool):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.use_stylo = use_stylo\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, i: int):\n",
        "        row  = self.df.iloc[i]\n",
        "        lang = row[\"language\"]\n",
        "        code = row.get(\"code_clean\", row[\"code\"])\n",
        "\n",
        "        # prepend a lightweight language tag the model can latch onto\n",
        "        text = f\"<lang:{lang}>\\n{code}\"\n",
        "\n",
        "        enc = self.tok(\n",
        "            text,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",   # stable VRAM; switch to \"longest\" + custom collate if you want dynamic padding\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            \"input_ids\":       enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\":  enc[\"attention_mask\"].squeeze(0),\n",
        "            \"label\":           torch.tensor(int(row[\"label_bin\"]), dtype=torch.float32),  # float for BCEWithLogits\n",
        "            \"language\":        lang,\n",
        "        }\n",
        "        if cfg.use_stylo:\n",
        "            item[\"stylo\"] = torch.tensor(basic_stylo(code, lang), dtype=torch.float32)\n",
        "\n",
        "        # quick sanity: attn mask is 0/1\n",
        "        # (comment this assert out if you’re micro-optimizing speed)\n",
        "        am = item[\"attention_mask\"]\n",
        "        if torch.numel(am) and not torch.all((am == 0) | (am == 1)):\n",
        "            raise ValueError(\"attention_mask contains values other than {0,1}\")\n",
        "\n",
        "        return item\n",
        "\n",
        "\n",
        "# ---- Dataloaders (stable defaults for Colab/A100) ----\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    StarCoderDataset(train_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,               # set >0 if your runtime is stable and disk is fast\n",
        "    pin_memory=True,\n",
        "    persistent_workers=False,\n",
        "    generator=g,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    StarCoderDataset(val_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "    batch_size=cfg.eval_bs,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    StarCoderDataset(test_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "    batch_size=cfg.eval_bs,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=False,\n",
        ")\n",
        "\n",
        "print(f\"batches → train={len(train_loader)}  val={len(val_loader)}  test={len(test_loader)}\")\n",
        "\n",
        "# quick sanity\n",
        "b = next(iter(train_loader))\n",
        "vsz = tok.vocab_size\n",
        "assert b[\"input_ids\"].min().item() >= 0 and b[\"input_ids\"].max().item() < vsz\n",
        "assert set(np.unique(b[\"attention_mask\"].numpy()).tolist()) <= {0,1}\n",
        "print(\"✅ batch OK | ids:\", tuple(b[\"input_ids\"].shape), \"| attn:\", tuple(b[\"attention_mask\"].shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu_h5T0gV6wG",
        "outputId": "2eb70864-c283-4932-c81b-56491ac41211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batches → train=500000  val=100000  test=1000\n",
            "✅ batch OK | ids: (1, 2048) | attn: (1, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 — StarCoder2-3B + LoRA classification head"
      ],
      "metadata": {
        "id": "sft-Yo0DWcTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 4 — Build StarCoder2-3B + LoRA binary classifier (lean + stable) ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# Free any previous model\n",
        "for n in [\"model\", \"base\"]:\n",
        "    if n in globals():\n",
        "        del globals()[n]\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 1) Load base LM (bf16 on Ampere/Lovelace if enabled, else fp16)\n",
        "amp_dtype = torch.bfloat16 if getattr(cfg, \"use_bf16\", False) else torch.float16\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    cfg.model_name,\n",
        "    torch_dtype=amp_dtype,\n",
        "    device_map=None\n",
        ").to(device)\n",
        "\n",
        "# 2) Make tokenizer/model consistent\n",
        "base.resize_token_embeddings(len(tok))\n",
        "base.config.pad_token_id = tok.pad_token_id\n",
        "base.config.eos_token_id = tok.eos_token_id\n",
        "base.config.use_cache    = False  # must be False when using grad checkpointing\n",
        "\n",
        "# 3) Pick LoRA target modules that actually exist — prefer only attention proj heads to save VRAM\n",
        "candidates_all = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"c_proj\",\"fc_in\",\"fc_out\",\"out_proj\"]\n",
        "present = [name.split(\".\")[-1] for name, _ in base.named_modules() if name.split(\".\")[-1] in candidates_all]\n",
        "present = sorted(set(present))\n",
        "# keep only q/k/v/o if available (best bang-for-buck); fall back to whatever is present\n",
        "preferred = [m for m in [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"c_proj\"] if m in present]\n",
        "target_modules = preferred if len(preferred) >= 3 else (present if present else cfg.lora_target_modules)\n",
        "print(\"LoRA targets:\", target_modules)\n",
        "\n",
        "# 4) LoRA config & wrap\n",
        "peft_cfg = LoraConfig(\n",
        "    r=cfg.lora_r,\n",
        "    lora_alpha=cfg.lora_alpha,\n",
        "    lora_dropout=cfg.lora_dropout,\n",
        "    target_modules=target_modules,\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    inference_mode=False,\n",
        ")\n",
        "base = get_peft_model(base, peft_cfg)\n",
        "\n",
        "# 5) Small binary head on pooled last hidden (optionally fuse 24-D stylometrics)\n",
        "class BinaryHead(nn.Module):\n",
        "    def __init__(self, hidden_size: int, use_stylo: bool, stylo_dim: int = 24):\n",
        "        super().__init__()\n",
        "        self.use_stylo = use_stylo\n",
        "        in_dim = hidden_size + (stylo_dim if use_stylo else 0)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, 1),\n",
        "        )\n",
        "    def forward(self, pooled: torch.Tensor, stylo: torch.Tensor | None):\n",
        "        if self.use_stylo and (stylo is not None):\n",
        "            pooled = torch.cat([pooled, stylo], dim=1)\n",
        "        return self.net(pooled).squeeze(-1)\n",
        "\n",
        "class StarcoderDetector(nn.Module):\n",
        "    def __init__(self, lm, use_stylo=True, stylo_dim=24):\n",
        "        super().__init__()\n",
        "        self.lm = lm\n",
        "        self.use_stylo = use_stylo\n",
        "        self.head = BinaryHead(lm.config.hidden_size, use_stylo, stylo_dim)\n",
        "    def forward(self, input_ids, attention_mask, stylo=None):\n",
        "        out = self.lm(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            use_cache=False,\n",
        "            return_dict=True,\n",
        "        )\n",
        "        h = out.hidden_states[-1]            # [B, L, H]\n",
        "        mask = attention_mask.unsqueeze(-1)  # [B, L, 1]\n",
        "        pooled = (h * mask).sum(1) / mask.sum(1).clamp(min=1)  # mean-pool\n",
        "        return self.head(pooled, stylo)\n",
        "\n",
        "model = StarcoderDetector(base, use_stylo=cfg.use_stylo, stylo_dim=24).to(device)\n",
        "\n",
        "# 6) Freeze all but LoRA + head\n",
        "for n, p in model.named_parameters():\n",
        "    if (\"lora\" in n.lower()) or (\"adapter\" in n.lower()) or (\"head\" in n.lower()):\n",
        "        p.requires_grad_(True)\n",
        "    else:\n",
        "        p.requires_grad_(False)\n",
        "\n",
        "# 7) Enable gradient checkpointing (big memory saver for long sequences)\n",
        "try:\n",
        "    model.lm.gradient_checkpointing_enable()\n",
        "    # also recommended when using checkpointing with HF models\n",
        "    if hasattr(model.lm, \"enable_input_require_grads\"):\n",
        "        model.lm.enable_input_require_grads()\n",
        "    print(\"✓ gradient checkpointing enabled; use_cache=False\")\n",
        "except Exception as e:\n",
        "    print(\"! could not enable gradient checkpointing:\", repr(e))\n",
        "\n",
        "# 8) Friendly summary\n",
        "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total     = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable: {trainable:,} / {total:,}  ({trainable/total:.2%})\")\n",
        "\n",
        "# 9) Fast math (safe on Ampere/Lovelace/Hopper)\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "08a8988a35c54a338efd8104970956a1",
            "505c8d99a7304cb4a2c70ddcd8d631cd",
            "c121003aebbf48be9269ff099cf87ad5",
            "10182ef9d86e497985fc16e772cce2b5",
            "21262084dd77494d8509e1f25c7045f3",
            "ffb025384b6b483d8eace538f8fe8b07",
            "8c72470ea6244bdfbe57414512ace245",
            "c84db0f7ac2c4f13812c1e7703db2c78",
            "b9172c0ebd384bf2ad118179aa20013e",
            "27e14e2931f54e94a670dcdf7a741f3d",
            "c420c293ab9040759cdee41212e61660",
            "0e05b590103645aeb291c931fd74b198",
            "3847a3c6d35b4e7fa44349b429ce0b64",
            "b99266977e824c989744c55f211f6db3",
            "9d5033de6d48447abd6238f22536fe41",
            "7ae0952adf744c819645e34d4e88adc2",
            "01586cc533d04754be81b00072666a07",
            "0cd0a5e6c1544a46b62d71e3d1aeddd3",
            "fe8ec2a1c5ac43a3924cb6147c7c2317",
            "3230cdcf020e40e7b2eab212432e9574",
            "51fb9606892a462ea321d3756ed579c1",
            "5ca64124252e484495f960332f0e8d25"
          ]
        },
        "id": "svvwL5ipXC02",
        "outputId": "61d7f2f1-9246-4004-e114-bbd8f13a1970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08a8988a35c54a338efd8104970956a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/12.1G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e05b590103645aeb291c931fd74b198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA targets: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'c_proj']\n",
            "✓ gradient checkpointing enabled; use_cache=False\n",
            "Trainable: 18,052,097 / 3,048,423,425  (0.59%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 5 — Train + Save Best (fp16 AMP, grad-accum, StarCoder2-3B + LoRA)"
      ],
      "metadata": {
        "id": "Zk5QVBG3Y0Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VRAM-safe knobs (L4) ---\n",
        "import os, torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1) Make allocations less bursty and allow TF32 matmul\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# 2) Tighten sequence length and micro-batch training\n",
        "cfg.max_len     = min(getattr(cfg, \"max_len\", 1536), 1024)  # 1024 is much safer than 1536/2048 on L4\n",
        "cfg.batch_size  = 8                                         # micro-batch = 1\n",
        "cfg.grad_accum  = max(getattr(cfg, \"grad_accum\", 8), 16)    # keep effective batch via accumulation\n",
        "cfg.eval_bs     = 8                                         # eval can be >1 (no grads)\n",
        "\n",
        "# 3) If needed, you can temporarily disable stylo to shave tiny compute (VRAM difference is small)\n",
        "# cfg.use_stylo = False\n",
        "\n",
        "# 4) Rebuild dataloaders with the new batch sizes\n",
        "train_loader = DataLoader(StarCoderDataset(train_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "                          batch_size=cfg.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader   = DataLoader(StarCoderDataset(val_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "                          batch_size=cfg.eval_bs, shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader  = DataLoader(StarCoderDataset(test_df, tok, cfg.max_len, cfg.use_stylo),\n",
        "                          batch_size=cfg.eval_bs, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "print(f\"✅ loaders rebuilt: train={len(train_loader)} iters, val={len(val_loader)} iters, test={len(test_loader)} iters\")\n",
        "print(f\"cfg.max_len={cfg.max_len} | train bs={cfg.batch_size} | grad_accum={cfg.grad_accum} | eval bs={cfg.eval_bs}\")\n",
        "\n",
        "# 5) Enable gradient checkpointing on the base LM and disable cache\n",
        "try:\n",
        "    model.lm.gradient_checkpointing_enable()\n",
        "    model.lm.config.use_cache = False\n",
        "    print(\"✓ gradient checkpointing enabled; use_cache=False\")\n",
        "except Exception as e:\n",
        "    print(\"! could not enable gradient checkpointing:\", repr(e))\n",
        "\n",
        "# 6) Show effective tokens per optimizer step (for sanity)\n",
        "eff_tokens = cfg.batch_size * cfg.grad_accum * cfg.max_len\n",
        "print(f\"~ effective tokens/optimizer-step ≈ {eff_tokens:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq8EStX9oxpW",
        "outputId": "f2860761-e430-4f45-919c-3ca56df654a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ loaders rebuilt: train=62500 iters, val=12500 iters, test=125 iters\n",
            "cfg.max_len=1024 | train bs=8 | grad_accum=16 | eval bs=8\n",
            "✓ gradient checkpointing enabled; use_cache=False\n",
            "~ effective tokens/optimizer-step ≈ 131,072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 5 — Train (caps or full), VAL/TEST, CSV — FIXED\n",
        "# =====================================================================\n",
        "from typing import Optional\n",
        "import os, numpy as np, pandas as pd, torch\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# ----- precision for autocast -----\n",
        "AMP_DTYPE = torch.bfloat16 if (getattr(cfg, \"use_bf16\", False) and torch.cuda.is_bf16_supported()) else torch.float16\n",
        "\n",
        "# ----- speed / memory knobs (edit as you like) -----\n",
        "TRAIN_MAX_BATCHES = 6250       # None = full epoch; set e.g. 4000 for a quick pass\n",
        "VAL_MAX_BATCHES   = 3125       # None = full validation; set e.g. 2000 for quick val\n",
        "\n",
        "# (If you run out of memory at start of training, you can temporarily do:\n",
        "# cfg.max_len = min(cfg.max_len, 1024); cfg.grad_accum = max(cfg.grad_accum, 16))\n",
        "\n",
        "# ----- rebuild (larger) VAL/TEST loaders if needed -----\n",
        "from torch.utils.data import DataLoader\n",
        "VAL_BS, TEST_BS = cfg.eval_bs, cfg.eval_bs  # keep what you set in CFG\n",
        "val_loader  = DataLoader(val_loader.dataset,  batch_size=VAL_BS,  shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(test_loader.dataset, batch_size=TEST_BS, shuffle=False, num_workers=0, pin_memory=True)\n",
        "print(f\"VAL batches:  {len(val_loader)}  (bs={VAL_BS})\")\n",
        "print(f\"TEST batches: {len(test_loader)} (bs={TEST_BS})\")\n",
        "\n",
        "# ----- per-language inverse-frequency weights (sqrt), mean≈1 -----\n",
        "lang_counts = pd.concat([train_df, val_df], ignore_index=True)[\"language\"].value_counts().to_dict()\n",
        "lang_w = {L: (1.0 / (c ** 0.5)) for L, c in lang_counts.items()}\n",
        "mw = sum(lang_w.values()) / max(1, len(lang_w))\n",
        "lang_w = {k: v / max(mw, 1e-8) for k, v in lang_w.items()}\n",
        "\n",
        "def batch_lang_w(batch_langs):\n",
        "    if not cfg.lang_reweight:\n",
        "        return None\n",
        "    return torch.tensor([lang_w.get(L, 1.0) for L in batch_langs], dtype=torch.float32, device=device)\n",
        "\n",
        "# ----- optimizer & scheduler -----\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.AdamW(params, lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "total_train_batches = len(train_loader) if TRAIN_MAX_BATCHES is None else min(len(train_loader), TRAIN_MAX_BATCHES)\n",
        "total_steps  = (total_train_batches * cfg.epochs) // max(1, cfg.grad_accum)\n",
        "warmup_steps = int(cfg.warmup_ratio * total_steps)\n",
        "scheduler    = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\n",
        "VOCAB = tok.vocab_size\n",
        "def sanitize(ids, attn):\n",
        "    attn = attn.long().clamp_(0, 1)\n",
        "    if ids.max().item() >= VOCAB or ids.min().item() < 0:\n",
        "        ids = ids.clone().clamp_(0, VOCAB - 1)\n",
        "    return ids, attn\n",
        "\n",
        "def metrics_bin(y_true, y_prob, thr=0.5):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, y_prob)\n",
        "    except Exception:\n",
        "        auroc = float(\"nan\")\n",
        "    auprc = average_precision_score(y_true, y_prob)\n",
        "    y_pred = (y_prob >= thr).astype(int)\n",
        "    return dict(\n",
        "        AUROC=float(auroc),\n",
        "        AUPRC=float(auprc),\n",
        "        MacroF1=float(f1_score(y_true, y_pred, average=\"macro\")),\n",
        "        Accuracy=float(accuracy_score(y_true, y_pred)),\n",
        "    ), y_pred\n",
        "\n",
        "def train_epoch(ep: int):\n",
        "    model.train()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    running, steps, skipped, opt_steps = 0.0, 0, 0, 0\n",
        "    n_batches = len(train_loader) if TRAIN_MAX_BATCHES is None else min(len(train_loader), TRAIN_MAX_BATCHES)\n",
        "\n",
        "    with tqdm(total=n_batches, desc=f\"Epoch {ep}\", unit=\"batch\") as pbar:\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            if (TRAIN_MAX_BATCHES is not None) and (i >= TRAIN_MAX_BATCHES):\n",
        "                break\n",
        "\n",
        "            ids   = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            attn  = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            lab   = batch[\"label\"].float().to(device, non_blocking=True)\n",
        "            sty   = batch.get(\"stylo\")\n",
        "            sty   = (sty.to(device, non_blocking=True) if (sty is not None and cfg.use_stylo) else None)\n",
        "\n",
        "            w_ex = batch_lang_w(batch[\"language\"])\n",
        "            if w_ex is None:\n",
        "                w_ex = torch.ones_like(lab, device=device)\n",
        "\n",
        "            ids, attn = sanitize(ids, attn)\n",
        "\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE):\n",
        "                logits = model(ids, attn, stylo=sty)\n",
        "                loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "                    logits.float(), lab.float(), weight=w_ex.float()\n",
        "                )\n",
        "\n",
        "            if not torch.isfinite(loss):\n",
        "                skipped += 1\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                pbar.set_postfix(loss=\"nan\", skipped=skipped); pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            if (i + 1) % cfg.grad_accum == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                scheduler.step()\n",
        "                opt_steps += 1\n",
        "\n",
        "            # light VRAM defrag every 200 steps\n",
        "            if (i + 1) % 200 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            running += float(loss.item()); steps += 1\n",
        "            pbar.set_postfix(loss=running / max(1, steps), skipped=skipped); pbar.update(1)\n",
        "\n",
        "    return running / max(1, steps), skipped\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(loader, desc=\"Validating\", thr=0.5, max_batches: Optional[int] = None):\n",
        "    model.eval()\n",
        "    probs, labels, langs = [], [], []\n",
        "    n_batches = len(loader) if (max_batches is None) else min(len(loader), max_batches)\n",
        "    with tqdm(total=n_batches, desc=desc, unit=\"batch\") as pbar:\n",
        "        for i, batch in enumerate(loader):\n",
        "            if (max_batches is not None) and (i >= max_batches):\n",
        "                break\n",
        "            ids  = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            attn = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            sty  = batch.get(\"stylo\")\n",
        "            sty  = (sty.to(device, non_blocking=True) if (sty is not None and cfg.use_stylo) else None)\n",
        "            ids, attn = sanitize(ids, attn)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE):\n",
        "                logits = model(ids, attn, stylo=sty)\n",
        "            probs.extend(torch.sigmoid(logits).float().cpu().numpy().tolist())\n",
        "            labels.extend(batch[\"label\"].cpu().numpy().tolist())\n",
        "            langs.extend(list(batch[\"language\"]))\n",
        "            pbar.update(1)\n",
        "    metrics, preds = metrics_bin(labels, probs, thr=thr)\n",
        "    return metrics, np.array(labels), np.array(probs), np.array(preds), np.array(langs)\n",
        "\n",
        "# ----- Train + Save best by MacroF1 -----\n",
        "best_f1, best_state = -1.0, None\n",
        "for ep in range(1, cfg.epochs + 1):\n",
        "    tr_loss, skipped = train_epoch(ep)\n",
        "\n",
        "    val_cap = VAL_MAX_BATCHES  # None → full val\n",
        "    val_metrics, v_labels, v_probs, v_preds, v_langs = eval_epoch(\n",
        "        val_loader, desc=\"Validating (VAL)\", thr=0.5, max_batches=val_cap\n",
        "    )\n",
        "    print(f\"\\nEpoch {ep}/{cfg.epochs} | skipped={skipped} | TrainLoss {tr_loss:.4f} | \"\n",
        "          f\"VAL → AUROC {val_metrics['AUROC']:.4f}  AUPRC {val_metrics['AUPRC']:.4f}  \"\n",
        "          f\"F1 {val_metrics['MacroF1']:.4f}  Acc {val_metrics['Accuracy']:.4f}\")\n",
        "\n",
        "    if val_metrics[\"MacroF1\"] > best_f1:\n",
        "        best_f1 = val_metrics[\"MacroF1\"]\n",
        "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
        "        print(\"** new best checkpoint cached **\")\n",
        "\n",
        "# save best\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "ckpt_path = os.path.join(cfg.out_dir, cfg.ckpt_name)\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state); model.to(device)\n",
        "    torch.save(best_state, ckpt_path)\n",
        "    print(\"✅ Saved best to:\", ckpt_path)\n",
        "else:\n",
        "    print(\"⚠️ No best state captured — check logs.\")\n",
        "\n",
        "# ----- Final VAL (full) -----\n",
        "final_val_metrics, v_labels, v_probs, v_preds, v_langs = eval_epoch(\n",
        "    val_loader, desc=\"Scoring VAL (final)\", thr=0.5, max_batches=3125\n",
        ")\n",
        "print(\"\\n=== VAL (final) ===\")\n",
        "print(final_val_metrics)\n",
        "print(\"\\nConfusion matrix (VAL):\\n\", confusion_matrix(v_labels, v_preds, labels=[0,1]))\n",
        "\n",
        "# ----- TEST + CSV -----\n",
        "test_metrics, t_labels, t_probs, t_preds, t_langs = eval_epoch(\n",
        "    test_loader, desc=\"Scoring TEST\", thr=0.5, max_batches=None\n",
        ")\n",
        "print(\"\\n=== TEST ===\")\n",
        "print(test_metrics)\n",
        "\n",
        "test_out = test_df.copy()\n",
        "test_out[\"prob_machine\"] = t_probs\n",
        "test_out[\"pred_label\"]   = t_preds\n",
        "csv_path = os.path.join(cfg.out_dir, \"taskA_test_with_predictions_starcoder2.csv\")\n",
        "test_out.to_csv(csv_path, index=False)\n",
        "print(\"📄 wrote:\", csv_path)\n",
        "\n",
        "print(\"\\nConfusion matrix (TEST):\\n\", confusion_matrix(t_labels, t_preds, labels=[0,1]))\n",
        "\n",
        "print(\"\\n=== Per-language (TEST) ===\")\n",
        "for lang in sorted(pd.unique(pd.Series(t_langs))):\n",
        "    m = (t_langs == lang)\n",
        "    if m.sum() == 0:\n",
        "        continue\n",
        "    met, _ = metrics_bin(t_labels[m], t_probs[m])\n",
        "    print(f\"{lang:>10s}  n={m.sum():5d}  Acc={met['Accuracy']:.3f}  F1={met['MacroF1']:.3f}  AUROC={met['AUROC']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719,
          "referenced_widgets": [
            "c88236cf5cc043fea0810f55407da2fc",
            "64ca4a69541f4d489e4f4b63d0e7f26b",
            "03eeeb2f0b0c4bd7a52cb663f29ec73b",
            "7544a0963cde482fba2ebb333c81af22",
            "b312c18ed85b4125b367ef604a0cb715",
            "7b27a6037cf041f9bd5054daee645177",
            "8d1a1a643d1543938ee3413757d95f40",
            "a8a53a12ea6d47fbad06ce600df062ed",
            "9d5226568cc64330a61f250af8ef9fe4",
            "10a340de31fd4577bc81558dbc054a42",
            "60efe570e5d445b691b3e21bc3f790e8",
            "469f4d83d5974911a83f22b73cffb6ce",
            "7b9f524313cb4413ac31108e88f8cc1b",
            "294e35a3ceb74cb98b1d00bb71ed7e14",
            "3c4fba002100479ebba71d9d404f5c36",
            "50e4c9b8210545ebade3906343e5c2db",
            "3091ec7159d443b88e84deed05d9a703",
            "893f03937a7f48e5a80279f2ce597b35",
            "d5b1625c46df4012ab8f7d6c9db781d3",
            "e35f44164a724b7aad26982e09ddfe8b",
            "742a342d16a648acbe5bb693dbe0f755",
            "765c8fcbf04341eea4cdf5969d2597de",
            "aa9edf2e119845e0a518af7ce8072d0b",
            "d0d87ddeb98948b2aaedf3b15c0c0fa6",
            "d04e39eb0a614e2c8db459a0ce9d5c28",
            "a2fcbc22065a457fa488b4afd62ec669",
            "f0550b33ebef47508942dab8e1acc41e",
            "4f14a40f0dc04a639cfe9cccbb0c68d1",
            "823c98cdb7c741589d36c0ae68431b7b",
            "704388380ec14c3d8a525079b1e0a5a7",
            "f13a24e98cac4b469164d342113d9322",
            "efe70aa9c83e4bfb8fae7c09307a4a49",
            "892ec6631e7849e2a6184487dc13ae5f",
            "7a593adb7a134868b467f5411854cb1f",
            "0e303518c64345edbf504102067abd82",
            "74d4b52bffb34c08b0a572807129e566",
            "63b81b1bd87c427f83953e258ac89d8e",
            "ea8ce5f7ed5048d287105123e8d9cb63",
            "fbac2def35ac4f508fb8d345d5b358b5",
            "d127020d25ce4cb5b925b08525ad7842",
            "ef54a7902edf4cfb80c544eeca0b8103",
            "365ea0a0b6fb4968b4e0ee8310a7dc8d",
            "ac09a8fac6304105a94c16053eeb4ae9",
            "350a818080044addb614c157062c2c38"
          ]
        },
        "id": "dvBzEKMfWe4g",
        "outputId": "f3c471d6-81fc-48a5-d620-6b4056a8f7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL batches:  12500  (bs=8)\n",
            "TEST batches: 125 (bs=8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1:   0%|          | 0/6250 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c88236cf5cc043fea0810f55407da2fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validating (VAL):   0%|          | 0/3125 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469f4d83d5974911a83f22b73cffb6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/1 | skipped=0 | TrainLoss 0.1524 | VAL → AUROC 0.9630  AUPRC 0.9712  F1 0.9134  Acc 0.9137\n",
            "** new best checkpoint cached **\n",
            "✅ Saved best to: /content/drive/MyDrive/semeval_taskA_outputs_starcoder2_A100_full/taskA_starcoder2_A100_best.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scoring VAL (final):   0%|          | 0/3125 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa9edf2e119845e0a518af7ce8072d0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VAL (final) ===\n",
            "{'AUROC': 0.962994821365011, 'AUPRC': 0.9711613177017148, 'MacroF1': 0.9134237898266615, 'Accuracy': 0.91368}\n",
            "\n",
            "Confusion matrix (VAL):\n",
            " [[10741  1287]\n",
            " [  871 12101]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scoring TEST:   0%|          | 0/125 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a593adb7a134868b467f5411854cb1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST ===\n",
            "{'AUROC': 0.7234101494191181, 'AUPRC': 0.4590283249626303, 'MacroF1': 0.49994938758983704, 'Accuracy': 0.506}\n",
            "📄 wrote: /content/drive/MyDrive/semeval_taskA_outputs_starcoder2_A100_full/taskA_test_with_predictions_starcoder2.csv\n",
            "\n",
            "Confusion matrix (TEST):\n",
            " [[308 469]\n",
            " [ 25 198]]\n",
            "\n",
            "=== Per-language (TEST) ===\n",
            "         c  n=   51  Acc=0.667  F1=0.630  AUROC=0.877\n",
            "       cpp  n=   75  Acc=0.613  F1=0.577  AUROC=0.828\n",
            "    csharp  n=  122  Acc=0.508  F1=0.505  AUROC=0.757\n",
            "        go  n=   60  Acc=0.833  F1=0.740  AUROC=0.824\n",
            "      java  n=  256  Acc=0.492  F1=0.467  AUROC=0.758\n",
            "javascript  n=   85  Acc=0.494  F1=0.464  AUROC=0.608\n",
            "       php  n=   48  Acc=0.292  F1=0.271  AUROC=0.663\n",
            "    python  n=  303  Acc=0.436  F1=0.434  AUROC=0.760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 6 — Threshold tuning on VAL → final TEST + CSV"
      ],
      "metadata": {
        "id": "7xjO_bCuG5hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 6 — Tune threshold on VAL, then score TEST + write CSV ===\n",
        "import numpy as np, pandas as pd, torch, os\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "AMP_DTYPE = torch.bfloat16 if getattr(cfg, \"use_bf16\", False) and torch.cuda.is_bf16_supported() else torch.float16\n",
        "VOCAB = tok.vocab_size\n",
        "\n",
        "def sanitize(ids, attn, vocab_size=VOCAB):\n",
        "    attn = attn.long().clamp_(0,1)\n",
        "    if ids.max().item() >= vocab_size or ids.min().item() < 0:\n",
        "        ids = ids.clone().clamp_(0, vocab_size-1)\n",
        "    return ids, attn\n",
        "\n",
        "def metrics_bin(y_true, y_prob, thr=0.5):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    y_prob = np.asarray(y_prob).astype(float)\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, accuracy_score\n",
        "    try:\n",
        "        auroc = roc_auc_score(y_true, y_prob)\n",
        "    except Exception:\n",
        "        auroc = float(\"nan\")\n",
        "    auprc = average_precision_score(y_true, y_prob)\n",
        "    y_pred = (y_prob >= thr).astype(int)\n",
        "    return dict(AUROC=float(auroc), AUPRC=float(auprc),\n",
        "                MacroF1=float(f1_score(y_true, y_pred, average=\"macro\")),\n",
        "                Accuracy=float(accuracy_score(y_true, y_pred))), y_pred\n",
        "\n",
        "@torch.no_grad()\n",
        "def score_loader(loader, desc=\"Scoring\"):\n",
        "    model.eval()\n",
        "    probs, labels, langs = [], [], []\n",
        "    with tqdm(total=len(loader), desc=desc, unit=\"batch\") as pbar:\n",
        "        for batch in loader:\n",
        "            ids  = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            attn = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            sty  = batch.get(\"stylo\")\n",
        "            sty  = (sty.to(device, non_blocking=True) if (sty is not None and cfg.use_stylo) else None)\n",
        "            ids, attn = sanitize(ids, attn)\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=AMP_DTYPE):\n",
        "                logits = model(ids, attn, stylo=sty)\n",
        "            probs.extend(torch.sigmoid(logits).float().cpu().numpy().tolist())\n",
        "            labels.extend(batch[\"label\"].cpu().numpy().tolist())\n",
        "            langs.extend(list(batch[\"language\"]))\n",
        "            pbar.update(1)\n",
        "    return np.array(labels), np.array(probs), np.array(langs)\n",
        "\n",
        "# 1) VAL: get full probabilities\n",
        "v_labels, v_probs, v_langs = score_loader(val_loader, desc=\"Scoring VAL (full for threshold)\")\n",
        "\n",
        "# 2) Tune threshold to maximize Macro-F1 on VAL\n",
        "cand = np.linspace(0.05, 0.95, 181)  # 0.005 step\n",
        "best_f1, best_t = -1.0, 0.5\n",
        "for t in cand:\n",
        "    met, _ = metrics_bin(v_labels, v_probs, thr=t)\n",
        "    if met[\"MacroF1\"] > best_f1:\n",
        "        best_f1, best_t = met[\"MacroF1\"], t\n",
        "\n",
        "print(f\"\\n🎯 Tuned threshold on VAL: t* = {best_t:.3f}  (VAL Macro-F1={best_f1:.4f})\")\n",
        "\n",
        "# 3) Final VAL report @ tuned threshold\n",
        "val_metrics, v_preds = metrics_bin(v_labels, v_probs, thr=best_t)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n=== VAL (tuned) ===\")\n",
        "print(val_metrics)\n",
        "print(\"Confusion matrix (VAL):\\n\", confusion_matrix(v_labels, v_preds, labels=[0,1]))\n",
        "\n",
        "# 4) TEST: score fully and apply tuned threshold\n",
        "t_labels, t_probs, t_langs = score_loader(test_loader, desc=\"Scoring TEST (final)\")\n",
        "test_metrics, t_preds = metrics_bin(t_labels, t_probs, thr=best_t)\n",
        "print(\"\\n=== TEST (tuned threshold) ===\")\n",
        "print(test_metrics)\n",
        "print(\"Confusion matrix (TEST):\\n\", confusion_matrix(t_labels, t_preds, labels=[0,1]))\n",
        "\n",
        "# 5) Write TEST CSV\n",
        "test_out = test_df.copy()\n",
        "test_out[\"prob_machine\"] = t_probs\n",
        "test_out[\"pred_label\"]   = t_preds\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "csv_path = os.path.join(cfg.out_dir, f\"taskA_test_with_predictions_starcoder2_t{best_t:.3f}.csv\")\n",
        "test_out.to_csv(csv_path, index=False)\n",
        "print(\"📄 wrote:\", csv_path)"
      ],
      "metadata": {
        "id": "44cbe0woY4ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "dd68c2c5379242d5bee4f9748c5eed2a",
            "929987bb8725401baf726872c13af560",
            "6185c498aaee42248ffdf99a85754573",
            "b1d82c62c3b441c7971ef12dbdbc447c",
            "3fc7517f0d9046d78a6ebcff4eedca91",
            "048358a28fd0472b9d2c91b75e916148",
            "6f218600b3b441d396927ec3faa9cad9",
            "01d7e5b1ccfe4c2180ad6308504b406f",
            "901c91df81db40349985c2331471120d",
            "4db659e60ef7430692656cbe901b1a18",
            "e2b3bbdf85ab44608e1225688bb5054c"
          ]
        },
        "outputId": "da70c954-6d98-4662-82e3-fb1329ee43ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scoring VAL (full for threshold):   0%|          | 0/12500 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd68c2c5379242d5bee4f9748c5eed2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3507334777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# 1) VAL: get full probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mv_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_langs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Scoring VAL (full for threshold)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# 2) Tune threshold to maximize Macro-F1 on VAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3507334777.py\u001b[0m in \u001b[0;36mscore_loader\u001b[0;34m(loader, desc)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAMP_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstylo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-199608820.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, stylo)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_stylo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstylo_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstylo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         out = self.lm(\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1578\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/starcoder2/modeling_starcoder2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/starcoder2/modeling_starcoder2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    831\u001b[0m                 )\n\u001b[1;32m    832\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    834\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/starcoder2/modeling_starcoder2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2903\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         )\n\u001b[0;32m-> 2905\u001b[0;31m     return torch.layer_norm(\n\u001b[0m\u001b[1;32m   2906\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgqFjagKCw5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}